{
  "id": "crashloop-troubleshooting",
  "title": "CrashLoopBackOff / Repeated Pod Restarts",
  "category": "troubleshooting",
  "tags": [
    "crashloop",
    "crashloopbackoff",
    "restart",
    "oomkilled",
    "exit code",
    "liveness",
    "readiness"
  ],
  "summary": "Step-by-step playbook to root-cause pods that keep restarting, with clear commands for logs, events, exit codes, probes, and resource pressure.",
  "error_patterns": [
    "CrashLoopBackOff",
    "Back-off restarting failed container",
    "container .* exited with code",
    "Liveness probe failed",
    "Readiness probe failed",
    "OOMKilled",
    "Error: container .* not found"
  ],
  "recommended_tools": [
    "FIND_ISSUES",
    "GET_LOGS <ns>/<pod> --previous",
    "DESCRIBE Pod <ns>/<pod>",
    "GET_EVENTS <ns>",
    "TOP_PODS",
    "SEARCH_KNOWLEDGE crashloop oom exit code"
  ],
  "quick_fix": "kubectl logs -n <ns> <pod> --previous && kubectl describe pod -n <ns> <pod> | sed -n '/Events/,$p'",
  "symptoms": [
    "Pod status shows CrashLoopBackOff",
    "Container restarts multiple times (restarts > 3)",
    "Backoff delay increasing between restarts",
    "App never becomes Ready"
  ],
  "decision_tree": [
    "If exit code = 137 or reason OOMKilled -> increase memory limits/requests, inspect memory spikes (TOP_PODS).",
    "If exit code = 1/other and logs show stack trace/config missing -> fix app/config, redeploy.",
    "If exit code = 127 -> entrypoint/command missing; verify image, entrypoint script, permissions.",
    "If liveness/readiness probe failing in Events -> fix probe path/port/timeout; increase initialDelaySeconds/failureThreshold.",
    "If image errors in Events -> follow image-pull troubleshooting.",
    "If mounts/config errors -> verify ConfigMap/Secret/PVC exists and is mounted correctly."
  ],
  "common_causes": [
    {
      "cause": "Application error on startup",
      "exit_code": "1",
      "description": "App crashes due to bug or missing dependency/config.",
      "diagnosis": "kubectl logs -n <ns> <pod> --previous | head -n 80",
      "fix": "Fix the app/config, rebuild image if needed; redeploy."
    },
    {
      "cause": "OOMKilled (memory pressure)",
      "exit_code": "137",
      "description": "Container killed for exceeding memory limit.",
      "diagnosis": "kubectl describe pod -n <ns> <pod> | grep -i OOMKilled; check TOP_PODS.",
      "fix": "Raise memory request/limit, reduce footprint, or add node capacity."
    },
    {
      "cause": "Bad command/entrypoint",
      "exit_code": "127",
      "description": "Entrypoint/command not found or not executable.",
      "diagnosis": "Check logs for 'command not found'; inspect container image entrypoint/args.",
      "fix": "Correct command/args; ensure script is present and executable."
    },
    {
      "cause": "Probe failures",
      "description": "Liveness/readiness probe fails; kubelet restarts container.",
      "diagnosis": "Events show 'Liveness/Readiness probe failed'; logs may be clean.",
      "fix": "Fix probe path/port/response; relax timeouts/failureThreshold; add startupProbe if needed."
    },
    {
      "cause": "Missing configuration or mounts",
      "description": "ConfigMap/Secret/PVC missing or wrong key/path.",
      "diagnosis": "Logs show 'file not found'/'permission denied'; describe pod shows mount errors.",
      "fix": "Create/bind correct resources; fix volumeMounts/volume names/keys."
    },
    {
      "cause": "Segfault",
      "exit_code": "139",
      "description": "App segfaults (SIGSEGV).",
      "diagnosis": "Exit code 139 in Events/lastState; logs show segfault.",
      "fix": "Debug application, enable core dumps, upgrade dependencies."
    }
  ],
  "exit_code_reference": {
    "0": "Success - normal exit",
    "1": "Application error - check logs/config",
    "126": "Permission denied - check securityContext/FS perms",
    "127": "Command not found - check entrypoint/image",
    "137": "SIGKILL (OOMKilled) - increase memory",
    "139": "SIGSEGV (segfault) - debug app",
    "143": "SIGTERM - graceful shutdown"
  },
  "diagnostic_commands": [
    "kubectl get pod -n <ns> <pod> -o wide",
    "kubectl logs -n <ns> <pod> --previous | head -n 120",
    "kubectl describe pod -n <ns> <pod>",
    "kubectl get pod -n <ns> <pod> -o jsonpath='{.status.containerStatuses[*].lastState}'",
    "kubectl get events -n <ns> --sort-by=.lastTimestamp | tail -n 20",
    "kubectl top pods -A | head -n 30"
  ],
  "investigation_flow": [
    "1) Discover target: FIND_ISSUES or LIST_ALL Pod to get <ns>/<pod>.",
    "2) Logs (previous crash): kubectl logs -n <ns> <pod> --previous | head -n 120.",
    "3) Events/exit codes: kubectl describe pod -n <ns> <pod> | sed -n '/Events/,$p'.",
    "4) Identify exit code/reason (1=app, 137=OOM, 127=cmd not found, probe failures).",
    "5) If OOM: kubectl top pods -A; check limits/requests and increase or optimize.",
    "6) If probe failing: fix probe path/port/timing; add startupProbe for slow start.",
    "7) If config/mount issues: verify ConfigMap/Secret/PVC names/keys; fix volumeMounts.",
    "8) Confirm fix: delete/restart pod or rollout restart; ensure Ready and restarts stable."
  ]
}
