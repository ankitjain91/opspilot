[
  {
    "id": "kb-101",
    "title": "Cluster Connectivity & Authentication Errors",
    "category": "reference",
    "tags": ["kubectl", "cluster", "authentication", "connectivity", "contexts"],
    "summary": "Reference for diagnosing and fixing connectivity and authentication issues when talking to a Kubernetes cluster",

    "connectivity_basics": {
      "description": "Use these commands to inspect and fix local kubeconfig and API connectivity issues",
      "commands": [
        {
          "command": "kubectl config get-contexts",
          "description": "List all configured contexts",
          "when_to_use": "You are not sure which cluster you're targeting"
        },
        {
          "command": "kubectl config current-context",
          "description": "Show current Kubernetes context",
          "when_to_use": "Before running any command that can modify cluster resources"
        },
        {
          "command": "kubectl cluster-info",
          "description": "Show cluster master and DNS information",
          "when_to_use": "Verify that the API server is reachable"
        },
        {
          "command": "kubectl get --raw='/healthz'",
          "description": "Check API server liveness",
          "when_to_use": "kubectl commands are slow or failing intermittently"
        },
        {
          "command": "KUBECONFIG=<path> kubectl ...",
          "description": "Override default kubeconfig file for a command",
          "when_to_use": "You maintain multiple kubeconfigs and want to be explicit"
        }
      ]
    },

    "common_errors": [
      {
        "name": "No connection / DNS issues",
        "error_patterns": [
          "The connection to the server <host> was refused",
          "dial tcp: lookup <host>: no such host",
          "i/o timeout"
        ],
        "symptoms": [
          "All kubectl commands fail immediately",
          "Cluster previously worked but stopped after network/VPN change"
        ],
        "likely_causes": [
          "VPN / corporate network not connected",
          "Wrong API endpoint in kubeconfig",
          "Local DNS resolution issues",
          "Firewall blocking outbound traffic to API endpoint"
        ],
        "diagnostic_commands": [
          "kubectl cluster-info",
          "kubectl get --raw='/healthz'",
          "kubectl config view --minify",
          "dig <apiserver-host> or nslookup <apiserver-host>",
          "curl -vk https://<apiserver-host>:<port>/version"
        ],
        "fix_steps": [
          "Verify VPN or private network connectivity",
          "Check kubeconfig cluster.server URL is correct",
          "Test DNS resolution for the API host",
          "If needed, switch to a different context that is known-good",
          "If using a proxy, ensure HTTPS_PROXY/NO_PROXY are correctly set"
        ]
      },
      {
        "name": "Invalid or expired credentials",
        "error_patterns": [
          "Unauthorized",
          "You must be logged in to the server (Unauthorized)",
          "certificate has expired or is not yet valid",
          "x509: certificate signed by unknown authority"
        ],
        "symptoms": [
          "Cluster reachable but all requests are rejected",
          "Auth works for some users but not others"
        ],
        "likely_causes": [
          "Expired client certificate in kubeconfig",
          "OIDC token expired",
          "CA bundle in kubeconfig not matching cluster CA",
          "Misconfigured exec credential plugin (e.g. az, gcloud, aws)"
        ],
        "diagnostic_commands": [
          "kubectl config view --minify",
          "kubectl get --raw='/readyz?verbose'",
          "kubectl auth can-i get pods",
          "Check credential helper: e.g. `az account show`, `gcloud auth list`, `aws sts get-caller-identity`"
        ],
        "fix_steps": [
          "Re-authenticate using cloud CLI (az/gcloud/aws) and re-generate kubeconfig",
          "For client certs, obtain a new certificate and update kubeconfig",
          "Verify that certificate-authority-data or certificate-authority path are correct",
          "If using exec plugins, make sure the binary is installed and on PATH"
        ]
      },
      {
        "name": "Context misconfiguration",
        "error_patterns": [
          "error: unable to read client-cert",
          "error: context was not found for specified context"
        ],
        "symptoms": [
          "Only one context fails; others work fine",
          "Kubeconfig merges multiple clusters and some entries are stale"
        ],
        "likely_causes": [
          "Context pointing to a removed or renamed cluster",
          "Client certificate/key paths invalid on this machine",
          "KUBECONFIG environment variable pointing to wrong file"
        ],
        "diagnostic_commands": [
          "kubectl config get-contexts",
          "kubectl config view",
          "echo $KUBECONFIG"
        ],
        "fix_steps": [
          "Delete or rename invalid contexts: `kubectl config delete-context <ctx>`",
          "Re-import kubeconfig from cluster provider",
          "Fix file paths for client-certificate/client-key/CA if moved"
        ]
      }
    ],

    "diagnostic_workflows": {
      "cannot_connect_to_cluster": [
        "kubectl config current-context → confirm target cluster",
        "kubectl cluster-info → check if API is reachable and responding",
        "If connection refused/timeout → check VPN, firewall, DNS (dig/curl)",
        "If Unauthorized or x509 → inspect kubeconfig credentials and CA",
        "If still failing → test from another machine or use cloud-provider diagnostics"
      ],
      "suspicious_auth_failures_for_one_user": [
        "kubectl auth can-i get pods → test RBAC for the user",
        "Compare kubeconfig for working vs non-working user",
        "Check identity from cloud CLI vs expected identity in cluster bindings",
        "Review ClusterRoleBinding/RoleBinding for the user/group/service account"
      ]
    },

    "best_practices": {
      "safety": [
        "Avoid editing kubeconfig by hand unless you know what you are doing",
        "Keep separate kubeconfigs for prod vs non-prod and use KUBECONFIG env var carefully"
      ],
      "efficiency": [
        "Use a kubeconfig switcher (e.g. kubectx/kubens) and clear naming conventions for contexts",
        "Include environment/cluster name in your terminal prompt to avoid mistakes"
      ],
      "observability": [
        "For managed clusters, learn provider-specific health commands (az, gcloud, aws, etc.)",
        "Keep at least one known-good admin kubeconfig for break-glass scenarios"
      ]
    }
  },

  {
    "id": "kb-102",
    "title": "Node & Scheduling Issues",
    "category": "reference",
    "tags": ["nodes", "scheduling", "pending-pods", "cluster-capacity"],
    "summary": "Diagnosis and remediation for node-level problems and pod scheduling failures",

    "node_inspection": {
      "description": "Start with node status when pods are Pending or cluster looks unhealthy",
      "commands": [
        {
          "command": "kubectl get nodes",
          "description": "List nodes and high-level status",
          "what_to_look_for": ["NotReady", "SchedulingDisabled", "Unknown", "AGE vs last transition"]
        },
        {
          "command": "kubectl describe node <node-name>",
          "description": "Inspect node conditions, allocatable resources, and taints",
          "what_to_look_for": ["MemoryPressure", "DiskPressure", "PIDPressure", "NetworkUnavailable", "Ready"]
        },
        {
          "command": "kubectl top nodes",
          "description": "Check CPU/memory usage if metrics-server is installed",
          "when_to_use": "Pods are Pending with reason 'Insufficient cpu/memory'"
        }
      ]
    },

    "common_errors": [
      {
        "name": "Pods stuck in Pending",
        "error_patterns": [
          "PodScheduled=False",
          "0/3 nodes are available: 3 Insufficient cpu",
          "0/3 nodes are available: 1 node(s) had taint {key=value: NoSchedule}"
        ],
        "symptoms": [
          "Pods never start",
          "kubectl get pods shows STATUS=Pending for long time"
        ],
        "likely_causes": [
          "Cluster has insufficient capacity",
          "Pod requests (resources.requests) too high",
          "No nodes match nodeSelector, affinity, or topology constraints",
          "Node taints not tolerated by pods"
        ],
        "diagnostic_commands": [
          "kubectl describe pod <name> -n <ns> → Events section",
          "kubectl get nodes",
          "kubectl describe node <name>",
          "kubectl get pods -A | grep Pending"
        ],
        "fix_steps": [
          "Scale cluster nodes up or add larger node pool",
          "Reduce resource requests/limits if over-provisioned",
          "Inspect nodeSelector/affinity and ensure matching labels exist",
          "Add appropriate tolerations to pods or remove unnecessary taints"
        ]
      },
      {
        "name": "Node NotReady / Unknown",
        "error_patterns": [
          "Ready=False",
          "Ready=Unknown",
          "NodeNotReady",
          "NodeHasSufficientMemory/NodeHasDiskPressure events"
        ],
        "symptoms": [
          "Some or all nodes show NotReady",
          "Pods on those nodes are evicted or stuck in Terminating"
        ],
        "likely_causes": [
          "Kubelet crash or misconfiguration",
          "Network agent / CNI issue",
          "Node lost connection to control plane",
          "Disk full or pressure conditions"
        ],
        "diagnostic_commands": [
          "kubectl describe node <node>",
          "kubectl get pods -A -o wide | grep <node>",
          "On node: journalctl -u kubelet (if accessible)",
          "Check cloud-provider node health / VM status"
        ],
        "fix_steps": [
          "Investigate and restart kubelet if needed",
          "Verify node has network connectivity to API server",
          "Free disk space if DiskPressure is reported",
          "If node is permanently unhealthy, cordon and drain, then replace"
        ]
      },
      {
        "name": "Pods repeatedly evicted",
        "error_patterns": [
          "The node was low on resource: memory",
          "The node had condition: [DiskPressure]"
        ],
        "symptoms": [
          "Pods get Evicted status",
          "Events show eviction due to resource pressure"
        ],
        "likely_causes": [
          "Node under-provisioned for workload",
          "Background processes consuming resources",
          "Local ephemeral storage filling up"
        ],
        "diagnostic_commands": [
          "kubectl describe pod <evicted-pod>",
          "kubectl top node <node>",
          "kubectl describe node <node> → Allocatable vs Capacity"
        ],
        "fix_steps": [
          "Increase node size or add more nodes",
          "Tune resource requests/limits for workloads",
          "Enable eviction thresholds appropriately",
          "Clean up logs or ephemeral storage usage"
        ]
      }
    ],

    "diagnostic_workflows": {
      "pods_pending": [
        "kubectl get pods -A | grep Pending → identify affected namespaces",
        "kubectl describe pod <name> → read Events for scheduling errors",
        "If Insufficient cpu/memory → check `kubectl top nodes` and scaling options",
        "If taints/affinity/nodeSelector mismatch → compare pod spec to node labels/taints",
        "If no obvious reason → check scheduler logs (control plane) if accessible"
      ],
      "node_unhealthy": [
        "kubectl get nodes → identify NotReady/Unknown nodes",
        "kubectl describe node <name> → check conditions and recent events",
        "Check node VM health in cloud provider console",
        "If recoverable: restart kubelet / network agent; if not: cordon, drain, then replace node"
      ]
    },

    "best_practices": {
      "capacity_planning": [
        "Set realistic resource requests/limits for each workload",
        "Use cluster autoscaler where possible",
        "Monitor node CPU/memory/disk with alerts"
      ],
      "safety": [
        "Always cordon and drain nodes before maintenance",
        "Avoid manual pod deletion from failing nodes without understanding why"
      ]
    }
  },

  {
    "id": "kb-103",
    "title": "Pod Lifecycle & Container Runtime Errors",
    "category": "reference",
    "tags": ["pods", "containers", "crashloopbackoff", "imagepullbackoff"],
    "summary": "Detailed guidance for common pod lifecycle and container runtime failures",

    "status_overview": {
      "description": "Pod statuses that indicate issues and what they generally mean",
      "statuses": [
        {
          "status": "CrashLoopBackOff",
          "meaning": "Container starts, crashes, and kubelet keeps restarting it",
          "first_steps": ["kubectl logs", "kubectl logs --previous", "kubectl describe pod"]
        },
        {
          "status": "ImagePullBackOff / ErrImagePull",
          "meaning": "Kubelet cannot pull the container image",
          "first_steps": ["kubectl describe pod → Events", "Check image name and registry credentials"]
        },
        {
          "status": "Error",
          "meaning": "Pod terminated with non-zero exit code",
          "first_steps": ["kubectl logs", "Check container command/args and configuration"]
        },
        {
          "status": "OOMKilled",
          "meaning": "Container killed by kernel due to memory limit breach",
          "first_steps": ["kubectl describe pod → Last State", "Review memory limits and application usage"]
        },
        {
          "status": "Terminating (stuck)",
          "meaning": "Pod is being shut down but not completing",
          "first_steps": ["kubectl describe pod → check finalizers", "kubectl get events"]
        }
      ]
    },

    "common_errors": [
      {
        "name": "CrashLoopBackOff",
        "error_patterns": [
          "Back-off restarting failed container",
          "CrashLoopBackOff"
        ],
        "symptoms": [
          "Pod restarts repeatedly",
          "Restart count keeps increasing"
        ],
        "likely_causes": [
          "Application bug causing process to exit",
          "Missing configuration (env vars, config files, secrets)",
          "Startup depending on a service that is not ready",
          "Misconfigured liveness/readiness probes killing container"
        ],
        "diagnostic_commands": [
          "kubectl logs <pod> -n <ns> --tail=200",
          "kubectl logs <pod> -n <ns> --previous",
          "kubectl describe pod <pod> -n <ns>",
          "kubectl get pod <pod> -n <ns> -o yaml"
        ],
        "fix_steps": [
          "Inspect logs for stack traces or configuration errors",
          "Verify env vars (kubectl describe pod; kubectl get deploy -o yaml)",
          "Check liveness/readiness probes; relax thresholds if too aggressive",
          "Ensure dependencies (DB, external services) are reachable and ready"
        ]
      },
      {
        "name": "ImagePullBackOff / ErrImagePull",
        "error_patterns": [
          "Failed to pull image",
          "pull access denied",
          "repository does not exist or may require 'docker login'"
        ],
        "symptoms": [
          "Pod never starts and remains in ImagePullBackOff",
          "Events show image pull failures"
        ],
        "likely_causes": [
          "Wrong image name or tag",
          "Image not pushed to registry",
          "Missing or wrong imagePullSecret",
          "Registry network restrictions"
        ],
        "diagnostic_commands": [
          "kubectl describe pod <pod> -n <ns> → Events",
          "kubectl get secret -n <ns>",
          "Try docker/podman pull from the same registry"
        ],
        "fix_steps": [
          "Correct image name/tag in Deployment",
          "Push image to registry",
          "Create / fix imagePullSecret and reference it in pod spec",
          "For private registries, verify credentials and network access"
        ]
      },
      {
        "name": "OOMKilled",
        "error_patterns": [
          "OOMKilled",
          "signal: killed"
        ],
        "symptoms": [
          "Pod restarts with reason OOMKilled",
          "Node memory usage high for that pod"
        ],
        "likely_causes": [
          "Container memory limit too low",
          "Application memory leak",
          "Large in-memory caches not bounded"
        ],
        "diagnostic_commands": [
          "kubectl describe pod <pod> -n <ns> → Last State",
          "kubectl top pod <pod> -n <ns>",
          "kubectl get deploy <name> -n <ns> -o yaml → review resources"
        ],
        "fix_steps": [
          "Increase memory limit for the container",
          "Optimize application memory usage or add limits",
          "Use profiling tools to find leaks",
          "Add resource requests aligned with realistic usage"
        ]
      },
      {
        "name": "ContainerCannotRun / permission denied",
        "error_patterns": [
          "container has runAsNonRoot and image has non-numeric user (0)",
          "OCI runtime error",
          "permission denied"
        ],
        "symptoms": [
          "Container never starts, immediately fails",
          "SecurityContext constraints violated"
        ],
        "likely_causes": [
          "SecurityContext runAsNonRoot + image default user is root",
          "Filesystem permissions incorrect",
          "PodSecurityPolicy / Pod Security Standards",
          "Read-only root filesystem but application expects write access"
        ],
        "diagnostic_commands": [
          "kubectl describe pod <pod> -n <ns> → Events",
          "kubectl get pod <pod> -n <ns> -o yaml → securityContext, fsGroup",
          "kubectl exec into a debug pod on same node to inspect volume permissions"
        ],
        "fix_steps": [
          "Adjust securityContext or rebuild image with non-root user",
          "Fix directory ownership/permissions for writable paths",
          "Mount writable volumes for paths where the app writes"
        ]
      }
    ],

    "diagnostic_workflows": {
      "pod_crashes_immediately": [
        "kubectl describe pod <pod> -n <ns> → check Last State, Events",
        "kubectl logs <pod> -n <ns> --previous → capture crash logs",
        "Inspect environment (config, secrets, args) for misconfigurations",
        "Verify downstream services (DB, external APIs) are reachable",
        "If related to probes, temporarily disable liveness probe and re-test"
      ],
      "image_pull_failures": [
        "kubectl describe pod <pod> -n <ns> → copy exact error message",
        "Verify image exists in registry by pulling manually",
        "Check imagePullSecrets and service account configuration",
        "Update deployment with correct image or secret and redeploy"
      ]
    },

    "best_practices": {
      "observability": [
        "Standardize logging so CrashLoopBackOff always shows clear messages",
        "Expose health endpoints for probes instead of arbitrary commands"
      ],
      "resilience": [
        "Set appropriate resource requests/limits to avoid noisy neighbor issues",
        "Use readiness probe to keep traffic away from unready pods"
      ]
    }
  },

  {
    "id": "kb-104",
    "title": "Networking, Services, Ingress & DNS Issues",
    "category": "reference",
    "tags": ["networking", "services", "ingress", "dns", "cni"],
    "summary": "Playbooks for service discovery, connectivity, and ingress-related failures",

    "service_basics": {
      "description": "Start here when debugging in-cluster connectivity",
      "commands": [
        {
          "command": "kubectl get svc -n <namespace>",
          "description": "List services and type/clusterIP",
          "what_to_look_for": ["Correct type (ClusterIP/NodePort/LoadBalancer)", "Port/targetPort mapping"]
        },
        {
          "command": "kubectl describe svc <name> -n <namespace>",
          "description": "Inspect service selectors and endpoints",
          "what_to_look_for": ["Selector matches pods", "EndPoints section not empty"]
        },
        {
          "command": "kubectl get endpoints <name> -n <namespace>",
          "description": "Directly check endpoints for service",
          "when_to_use": "Service exists but no traffic reaches pods"
        }
      ]
    },

    "common_errors": [
      {
        "name": "Service resolves but no endpoints",
        "error_patterns": [
          "no endpoints available for service",
          "curl: (7) Failed to connect"
        ],
        "symptoms": [
          "DNS resolves service name but connection refused/timeout",
          "kubectl get endpoints <svc> shows empty subsets"
        ],
        "likely_causes": [
          "Service selector doesn't match pod labels",
          "Pods not Ready (readiness probes failing)",
          "Pods in different namespace than expected"
        ],
        "diagnostic_commands": [
          "kubectl describe svc <svc> -n <ns>",
          "kubectl get pods -n <ns> -l <service-selector>",
          "kubectl get endpoints <svc> -n <ns>"
        ],
        "fix_steps": [
          "Align service selector labels with pod template labels",
          "Fix readiness probe or pod health so endpoints become Ready",
          "Ensure correct namespace for both service and pods"
        ]
      },
      {
        "name": "DNS resolution failures",
        "error_patterns": [
          "temporary failure in name resolution",
          "no such host"
        ],
        "symptoms": [
          "Pods cannot resolve service names or external domains",
          "nslookup fails from within pods"
        ],
        "likely_causes": [
          "CoreDNS pod crash or misconfiguration",
          "Network policies blocking DNS",
          "Cluster DNS config broken (kube-dns service)"
        ],
        "diagnostic_commands": [
          "kubectl get pods -n kube-system -l k8s-app=kube-dns",
          "kubectl logs -n kube-system -l k8s-app=kube-dns",
          "kubectl get svc kube-dns -n kube-system",
          "kubectl exec -it <pod> -n <ns> -- nslookup kubernetes.default"
        ],
        "fix_steps": [
          "Restart or redeploy CoreDNS if necessary",
          "Check ConfigMap for CoreDNS for invalid config",
          "Ensure network policy allows UDP/TCP 53 to DNS pods"
        ]
      },
      {
        "name": "Ingress / HTTP 404 / SSL issues",
        "error_patterns": [
          "404 Not Found from ingress",
          "default backend - 404",
          "certificate is not valid for requested host"
        ],
        "symptoms": [
          "External traffic reaches ingress but not application",
          "TLS handshake errors"
        ],
        "likely_causes": [
          "Ingress host/path rules not matching request",
          "Backend service port mismatch",
          "Incorrect TLS secret or wrong certificate"
        ],
        "diagnostic_commands": [
          "kubectl get ingress -n <ns>",
          "kubectl describe ingress <name> -n <ns>",
          "kubectl get svc <backend> -n <ns>",
          "kubectl logs -n <ingress-ns> <ingress-controller-pod>"
        ],
        "fix_steps": [
          "Ensure host header in request matches Ingress spec",
          "Verify path definitions follow controller syntax (nginx, traefik, etc.)",
          "Confirm service port/targetPort align with pod containerPort",
          "Create correct TLS secret and reference it in the Ingress"
        ]
      },
      {
        "name": "Network policies blocking traffic",
        "error_patterns": [
          "Timeout when calling another service inside cluster",
          "Connection refused despite endpoints being ready"
        ],
        "symptoms": [
          "Only some pods/namespaces can talk to a service",
          "Newly added networkpolicy broke existing flows"
        ],
        "likely_causes": [
          "Default deny NetworkPolicy in namespace",
          "Missing egress/ingress rules for specific pods or namespaces"
        ],
        "diagnostic_commands": [
          "kubectl get networkpolicy -A",
          "kubectl describe networkpolicy <name> -n <ns>",
          "Use a temporary debug pod (e.g. busybox) to test connectivity"
        ],
        "fix_steps": [
          "Add explicit allow rules for required traffic",
          "Consider namespace-wide default policies carefully",
          "Use labels consistently to match workloads in policies"
        ]
      }
    ],

    "diagnostic_workflows": {
      "service_not_reachable_from_pod": [
        "From source pod: kubectl exec -it <pod> -- curl http://<svc>.<ns>.svc.cluster.local:<port>",
        "If DNS fails → debug CoreDNS (kube-dns pods, logs)",
        "If connection refused/timeouts → check service endpoints and pod readiness",
        "If endpoints exist and healthy → inspect NetworkPolicies and CNI logs"
      ],
      "ingress_issues": [
        "curl -v https://<host>/path → observe status code, response",
        "kubectl describe ingress <name> -n <ns> → verify hosts/paths/backend services",
        "Check Ingress controller logs for routing or SSL/TLS errors",
        "Validate TLS secret (CN/SANs) matches requested hostname"
      ]
    },

    "best_practices": {
      "design": [
        "Use fully-qualified service names when debugging cross-namespace issues",
        "Define default deny policies only after explicit allow rules are in place"
      ],
      "observability": [
        "Expose metrics and logs from ingress controller",
        "Set up synthetic checks for critical service endpoints"
      ]
    }
  },
  {
    "id": "kb-105",
    "title": "Storage, PersistentVolumes & Volume Mount Issues",
    "category": "reference",
    "tags": ["storage", "pvc", "pv", "csi", "volumes"],
    "summary": "Troubleshooting guide for PersistentVolumeClaims, storage classes, and volume mount failures",
    "storage_basics": {
      "description": "Inspect PVC, PV, and StorageClass when pods fail to mount volumes",
      "commands": [
        {
          "command": "kubectl get pvc -n <ns>",
          "description": "List PVCs and their status",
          "what_to_look_for": ["Pending", "Bound", "correct STORAGECLASS and CAPACITY"]
        },
        {
          "command": "kubectl describe pvc <name> -n <ns>",
          "description": "Check events for binding or provisioning errors"
        },
        {
          "command": "kubectl get pv",
          "description": "Check PersistentVolumes and reclaim policy"
        },
        {
          "command": "kubectl get storageclass",
          "description": "List storage classes and default class"
        }
      ]
    },
    "common_errors": [
      {
        "name": "PVC stuck in Pending",
        "error_patterns": [
          "waiting for a volume to be created, either by external provisioner or manually",
          "no persistent volumes available for this claim"
        ],
        "symptoms": [
          "Pods referencing PVC cannot start",
          "PVC never becomes Bound"
        ],
        "likely_causes": [
          "StorageClass missing or misconfigured",
          "No matching PV with required size/access mode",
          "CSI driver not running or misconfigured"
        ],
        "diagnostic_commands": [
          "kubectl describe pvc <pvc> -n <ns>",
          "kubectl get storageclass",
          "kubectl get pods -A | grep csi",
          "kubectl get pv"
        ],
        "fix_steps": [
          "Ensure correct StorageClass name in PVC spec",
          "Check that a dynamic provisioner (CSI) is deployed and healthy",
          "If using static provisioning, create a matching PV with correct size and access modes"
        ]
      },
      {
        "name": "Pod fails to mount volume",
        "error_patterns": [
          "MountVolume.MountDevice failed",
          "unable to mount volumes",
          "timeout expired waiting for volumes to attach or mount"
        ],
        "symptoms": [
          "Pod stuck in ContainerCreating",
          "Events show mount or attach errors"
        ],
        "likely_causes": [
          "Underlying cloud disk/volume not attaching to node",
          "Node lacks permissions to access storage APIs",
          "Filesystem type mismatch or corruption"
        ],
        "diagnostic_commands": [
          "kubectl describe pod <pod> -n <ns> → Events",
          "kubectl logs -n <csi-namespace> <csi-controller-pod>",
          "kubectl logs -n <csi-namespace> <csi-node-pod> -c csi-node"
        ],
        "fix_steps": [
          "Check cloud provider disk state and attachments",
          "Ensure node has required IAM/RBAC permissions for storage operations",
          "If FS is corrupted, consider recreating volume from backup or snapshot"
        ]
      },
      {
        "name": "ReadOnly filesystem or permission denied",
        "error_patterns": [
          "Read-only file system",
          "permission denied"
        ],
        "symptoms": [
          "App cannot write to mounted path",
          "Pod runs but app errors when writing"
        ],
        "likely_causes": [
          "volumeMount set to readOnly: true",
          "Filesystem permissions not matching container user/group",
          "ReadOnlyRootFilesystem enabled but writable paths not using separate volumes"
        ],
        "diagnostic_commands": [
          "kubectl get pod <pod> -n <ns> -o yaml → volumeMounts",
          "kubectl exec -it <pod> -n <ns> -- id; ls -l /path",
          "kubectl describe pvc/pv for reclaim policy and options"
        ],
        "fix_steps": [
          "Set readOnly: false if writes are required",
          "Adjust securityContext (runAsUser, fsGroup) to match filesystem ownership",
          "Mount dedicated writable volumes for app-specific paths"
        ]
      }
    ],

    "diagnostic_workflows": {
      "pvc_pending_or_pods_stuck_creating": [
        "kubectl get pvc -n <ns> → identify Pending PVCs",
        "kubectl describe pvc <name> -n <ns> → read provisioning events",
        "kubectl get storageclass → ensure default and targeted storageclass exist",
        "Verify CSI driver pods are Running and check their logs for errors",
        "If static provisioning used, check PV definitions for proper matching"
      ],
      "mount_failures": [
        "kubectl describe pod <pod> -n <ns> → see MountVolume errors",
        "Check underlying storage resource (disk/volume) in cloud provider",
        "Review node-level logs for CSI node plugin",
        "If needed, move pod to different node and test again"
      ]
    },

    "best_practices": {
      "design": [
        "Use dynamic provisioning with a well-tested CSI driver for most workloads",
        "Define clear StorageClasses per performance tier and region/zone"
      ],
      "safety": [
        "Understand reclaimPolicy (Delete vs Retain) before deleting PVC/PV",
        "Automate backups/snapshots for critical stateful workloads"
      ]
    }
  },
  {
    "id": "kb-106",
    "title": "Control Plane, API Server & Rate Limiting Issues",
    "category": "reference",
    "tags": ["control-plane", "apiserver", "etcd", "rate-limits"],
    "summary": "Troubleshooting slow or failing API server operations, etcd problems, and throttling",

    "api_health": {
      "description": "Quick checks for API server health and responsiveness",
      "commands": [
        {
          "command": "kubectl get --raw='/healthz'",
          "description": "Basic API server health"
        },
        {
          "command": "kubectl get --raw='/readyz?verbose'",
          "description": "Detailed readiness for control plane components"
        },
        {
          "command": "kubectl get componentstatuses",
          "description": "Legacy component status (where available)",
          "note": "Not always present in newer Kubernetes distributions"
        }
      ]
    },

    "common_errors": [
      {
        "name": "Slow kubectl / timeouts",
        "error_patterns": [
          "context deadline exceeded",
          "net/http: TLS handshake timeout"
        ],
        "symptoms": [
          "kubectl commands hang or time out",
          "Cluster dashboard/UI also slow or unresponsive"
        ],
        "likely_causes": [
          "High API server load or excessive watchers",
          "etcd under pressure or slow disk",
          "Network latency between you and the control plane"
        ],
        "diagnostic_commands": [
          "kubectl get --raw='/metrics' (if allowed) → inspect API metrics",
          "kubectl get events -A → look for control-plane related warnings",
          "Provider-specific diagnostic tools (e.g., az aks show, gcloud container clusters describe)"
        ],
        "fix_steps": [
          "Reduce watch-heavy controllers or add backoff in custom controllers",
          "Scale control plane (managed clusters may require SKU upgrade)",
          "For self-managed clusters, tune etcd (disk IOPS, defrag, compaction)"
        ]
      },
      {
        "name": "Too many requests / rate limiting",
        "error_patterns": [
          "Error from server (TooManyRequests):",
          "throttling request due to client-side rate limiting"
        ],
        "symptoms": [
          "Automation tools or controllers frequently get throttled",
          "kubectl occasionally receives 429 errors"
        ],
        "likely_causes": [
          "Single client doing many API calls without backoff",
          "Multiple controllers listing/watching large resource sets",
          "kubectl used in tight loops without rate limiting"
        ],
        "diagnostic_commands": [
          "kubectl get --raw='/metrics' | grep apiserver_request_total (if allowed)",
          "Check controller logs for throttling warnings",
          "Review custom operators/automation scripts for excessive API calls"
        ],
        "fix_steps": [
          "Add client-side rate limiting and exponential backoff",
          "Use informers and shared caches in custom controllers instead of frequent lists",
          "Shard workloads across namespaces or clusters to reduce API load"
        ]
      },
      {
        "name": "etcd health issues (self-managed clusters)",
        "error_patterns": [
          "failed to commit proposal",
          "rafthttp: request cluster ID mismatch",
          "etcdserver: mvcc: database space exceeded"
        ],
        "symptoms": [
          "API server errors or restarts",
          "Inconsistent view of cluster state"
        ],
        "likely_causes": [
          "etcd disk space usage exceeded quota",
          "Slow disk or network between etcd members",
          "Split-brain or quorum loss"
        ],
        "diagnostic_commands": [
          "etcdctl endpoint health (from control plane host)",
          "etcdctl alarm list",
          "df -h on etcd data disk"
        ],
        "fix_steps": [
          "If mvcc: database space exceeded → run etcd compaction and defrag",
          "Ensure sufficient disk IOPS and free space for etcd",
          "Restore quorum or restore from backup in disaster scenarios"
        ]
      }
    ],

    "diagnostic_workflows": {
      "kubectl_slow_or_unreliable": [
        "Test connectivity and latency: ping API endpoint, curl /healthz",
        "Check for rate limiting errors in client logs",
        "If managed cluster → consult provider health dashboard",
        "If self-managed → inspect API server and etcd logs, CPU/memory/disk metrics",
        "Mitigate by reducing API load and scaling control plane as needed"
      ]
    },

    "best_practices": {
      "design": [
        "Design controllers using shared informers and caches, not tight polling loops",
        "Avoid storing large objects or frequent updates in etcd"
      ],
      "reliability": [
        "Back up etcd regularly for self-managed clusters",
        "Use managed control planes where possible to offload operations"
      ]
    }
  },

  {
    "id": "kb-107",
    "title": "RBAC, Admission, Quotas & Policy Failures",
    "category": "reference",
    "tags": ["rbac", "admission", "webhook", "quota", "policy"],
    "summary": "Systematic approach to authorization errors, admission webhook failures, and resource quota issues",

    "rbac_basics": {
      "description": "Quick commands for RBAC debugging",
      "commands": [
        {
          "command": "kubectl auth can-i <verb> <resource> -n <ns>",
          "description": "Check if current identity is authorized for an action"
        },
        {
          "command": "kubectl auth can-i --list -n <ns>",
          "description": "List permitted actions for current identity"
        },
        {
          "command": "kubectl get rolebinding,clusterrolebinding -A | grep <user-or-sa>",
          "description": "Find bindings related to a specific subject"
        }
      ]
    },

    "common_errors": [
      {
        "name": "RBAC forbidden errors",
        "error_patterns": [
          "Error from server (Forbidden):",
          "User \"<name>\" cannot <verb> resource \"<resource>\" in API group"
        ],
        "symptoms": [
          "Specific operations fail while others work",
          "Admin account can perform action but regular user cannot"
        ],
        "likely_causes": [
          "Missing Role/ClusterRole or binding for the identity",
          "ServiceAccount used by pod lacks required permissions"
        ],
        "diagnostic_commands": [
          "kubectl auth can-i get pods -n <ns>",
          "kubectl get rolebinding -n <ns>",
          "kubectl get clusterrolebinding"
        ],
        "fix_steps": [
          "Create or update Role/ClusterRole with required rules",
          "Bind subject (User/Group/ServiceAccount) using RoleBinding or ClusterRoleBinding",
          "Avoid granting cluster-admin when more specific permissions suffice"
        ]
      },
      {
        "name": "Admission webhook rejections",
        "error_patterns": [
          "admission webhook \"<name>\" denied the request",
          "failed calling webhook",
          "no such host for webhook"
        ],
        "symptoms": [
          "Creating/updating specific resources fails consistently",
          "Errors reference validating/mutating webhooks"
        ],
        "likely_causes": [
          "Webhook policy intentionally blocking non-compliant resources",
          "Webhook server unreachable or misconfigured",
          "Invalid TLS configuration between API server and webhook"
        ],
        "diagnostic_commands": [
          "kubectl get mutatingwebhookconfigurations",
          "kubectl get validatingwebhookconfigurations",
          "kubectl describe validatingwebhookconfiguration <name>",
          "kubectl logs -n <webhook-ns> <webhook-pod>"
        ],
        "fix_steps": [
          "Read webhook error message and fix resource to meet policy",
          "If webhook server is down, restore it or, in emergency, disable/delete webhook",
          "Fix DNS/service name and TLS certs used by webhook"
        ]
      },
      {
        "name": "ResourceQuota and LimitRange violations",
        "error_patterns": [
          "exceeded quota",
          "must specify resources.cpu",
          "limit must be greater than or equal to request"
        ],
        "symptoms": [
          "Pod/Deployment creation fails in specific namespaces",
          "Errors include ResourceQuota or LimitRange details"
        ],
        "likely_causes": [
          "Namespace quotas fully consumed",
          "Requests/limits not set or out of allowed bounds",
          "New workloads exceed quota constraints"
        ],
        "diagnostic_commands": [
          "kubectl get resourcequota -n <ns>",
          "kubectl describe resourcequota <name> -n <ns>",
          "kubectl get limitrange -n <ns>",
          "kubectl describe limitrange <name> -n <ns>"
        ],
        "fix_steps": [
          "Adjust ResourceQuota or free resources by deleting unused workloads",
          "Set explicit requests/limits in pod specs that comply with LimitRanges",
          "Coordinate with cluster admins to increase quotas when justified"
        ]
      }
    ],

    "diagnostic_workflows": {
      "forbidden_or_denied": [
        "Run kubectl auth can-i <verb> <resource> -n <ns> as the failing identity",
        "If 'no' → inspect Role/ClusterRole/Bindings for that identity",
        "Grant least-privilege permissions needed and re-test",
        "If admission webhook denial → read exact error and adjust resource or webhook config"
      ]
    },

    "best_practices": {
      "security": [
        "Follow least-privilege RBAC design",
        "Separate human and machine identities with distinct roles"
      ],
      "governance": [
        "Document admission policies so developers know expected constraints",
        "Use warnings (where supported) before strict denials during rollout of new policies"
      ]
    }
  },

  {
    "id": "kb-108",
    "title": "Workload-Specific Issues: Deployments, Jobs, CronJobs, DaemonSets",
    "category": "reference",
    "tags": ["deployments", "jobs", "cronjobs", "daemonsets", "workloads"],
    "summary": "Common error patterns and workflows for core Kubernetes workloads",

    "deployment_issues": {
      "description": "Debugging rolling updates and replica management",
      "common_errors": [
        {
          "name": "Rollout stuck",
          "error_patterns": [
            "progressDeadlineExceeded",
            "ReplicaSet \"<name>\" has timed out progressing"
          ],
          "symptoms": [
            "kubectl rollout status deployment/<name> never completes",
            "Some pods failing while others are Running"
          ],
          "likely_causes": [
            "New pod version failing readiness or crashing",
            "Insufficient capacity for new replicas",
            "PodDisruptionBudget blocking progress"
          ],
          "diagnostic_commands": [
            "kubectl rollout status deployment/<name> -n <ns>",
            "kubectl describe deployment <name> -n <ns>",
            "kubectl get pods -n <ns> -l app=<name>",
            "kubectl get pdb -n <ns>"
          ],
          "fix_steps": [
            "Inspect new pod logs and fix configuration issues",
            "Scale cluster or adjust resource requests if capacity is low",
            "Relax or update PodDisruptionBudget if it's too strict"
          ]
        }
      ]
    },

    "job_and_cronjob_issues": {
      "description": "Troubleshooting one-off and scheduled tasks",
      "common_errors": [
        {
          "name": "Jobs never complete",
          "error_patterns": [
            "BackoffLimitExceeded",
            "DeadlineExceeded"
          ],
          "symptoms": [
            "Job pods repeatedly fail",
            "Job status shows failed attempts"
          ],
          "likely_causes": [
            "Job container exits with non-zero status",
            "Job activeDeadlineSeconds too low",
            "Resources insufficient for job to complete"
          ],
          "diagnostic_commands": [
            "kubectl describe job <name> -n <ns>",
            "kubectl get pods -n <ns> -l job-name=<name>",
            "kubectl logs -n <ns> <job-pod>"
          ],
          "fix_steps": [
            "Fix application logic or input data to avoid non-zero exit",
            "Increase backoffLimit or activeDeadlineSeconds if appropriate",
            "Increase resources or change node pool if required"
          ]
        },
        {
          "name": "CronJobs not running",
          "error_patterns": [
            "No Job objects created at expected times"
          ],
          "symptoms": [
            "kubectl get cronjob shows SCHEDULE but no recent jobs",
            "Jobs run at unexpected times"
          ],
          "likely_causes": [
            "Incorrect cron schedule expression",
            "Controller disabled in older cluster versions",
            "ConcurrencyPolicy or startingDeadlineSeconds constraints"
          ],
          "diagnostic_commands": [
            "kubectl describe cronjob <name> -n <ns>",
            "kubectl get jobs -n <ns> -l cronjob-name=<name>"
          ],
          "fix_steps": [
            "Validate cron expression using an external validator",
            "Verify controller-manager flags for CronJobs (self-managed clusters)",
            "Adjust startingDeadlineSeconds and concurrencyPolicy if too restrictive"
          ]
        }
      ]
    },

    "daemonset_issues": {
      "description": "Handling pods meant to run on every (or selected) node",
      "common_errors": [
        {
          "name": "DaemonSet pods missing on nodes",
          "error_patterns": [
            "0/3 nodes are available: 3 node(s) didn't match node selector"
          ],
          "symptoms": [
            "DaemonSet not creating pods on all expected nodes",
            "Some nodes have pods, others don't"
          ],
          "likely_causes": [
            "nodeSelector/tolerations/affinity not matching all target nodes",
            "Taints on nodes without tolerations for DaemonSet pods"
          ],
          "diagnostic_commands": [
            "kubectl get daemonset <name> -n <ns> -o wide",
            "kubectl describe daemonset <name> -n <ns>",
            "kubectl get nodes --show-labels",
            "kubectl describe node <node>"
          ],
          "fix_steps": [
            "Align nodeSelector and tolerations with target nodes",
            "Add tolerations for required taints or adjust taints on nodes",
            "Ensure DaemonSet uses hostNetwork/hostPID correctly if needed"
          ]
        }
      ]
    },

    "diagnostic_workflows": {
      "deployment_rollout_failure": [
        "kubectl rollout status deployment/<name> -n <ns> → see if rollout timed out",
        "kubectl get pods -n <ns> -l app=<name> → find failing pods",
        "kubectl logs and describe failing pods to identify config/image issues",
        "If necessary, rollback: kubectl rollout undo deployment/<name> -n <ns>"
      ],
      "job_failure": [
        "kubectl describe job <name> -n <ns> → read conditions and backoff limits",
        "kubectl get pods -n <ns> -l job-name=<name> → inspect pod statuses",
        "kubectl logs <job-pod> -n <ns> → gather error output",
        "Adjust job spec or environment and re-run"
      ]
    },

    "best_practices": {
      "operations": [
        "Use kubectl rollout status after every deployment change",
        "Set reasonable backoff and deadlines for Jobs",
        "Monitor CronJob history and failures"
      ]
    }
  }
]