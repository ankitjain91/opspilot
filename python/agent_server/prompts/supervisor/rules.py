
DECISION_RULES_PROMPT = """
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
DECISION FRAMEWORK (CHOOSE FIRST MATCHING RULE)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… SET next_action="respond" IMMEDIATELY (no kubectl needed) when:
  1. Greeting/off-topic: "hello", "hi", non-K8s requests
  2. Definitions: "what is a pod?", "explain X", "difference between A and B"
  3. Have root cause in command_history:
      â€¢ OOMKilled/Exit 137 â†’ Memory limit exceeded
      â€¢ ImagePullBackOff + 401/403/404 â†’ Auth/not found
      â€¢ CrashLoopBackOff + error logs â†’ App crash identified
      â€¢ FailedScheduling + Insufficient â†’ Resource quota/node issue
      â€¢ Any CRD with status.message showing error â†’ Root cause found
      â€¢ Liveness/Readiness probe failures with HTTP codes â†’ Application not ready
  4. All resources healthy in command_history:
      â€¢ SYNCED=True READY=True â†’ "All resources healthy"
      â€¢ All nodes Ready â†’ "Cluster healthy"
      â€¢ Empty result for "find failing" query â†’ "No issues found"
  5. For "Find/List/Health" queries: If you have gathered sufficient data (discovery + status checks), respond
      â€¢ âš ï¸ **CRITICAL**: If command_history is EMPTY or has <2 commands, you MUST create_plan! Never respond without investigation!
      â€¢ âš ï¸ **WAIT**: If last command was `kubectl api-resources` or discovery, you MUST try multiple discovery methods!
      â€¢ "List X" + only ran `api-resources | grep X` â†’ NOT READY, try `kubectl get pods,deployments,svc -A | grep -i X`
      â€¢ "Find cluster issues" + have checked pods/events/nodes â†’ Respond with analysis
      â€¢ "List failing pods" + have filtered results â†’ Respond with findings
      â€¢ "Check health" + have status from key resources â†’ Respond with summary
  6. Iteration > 2 AND have useful command output â†’ Don't keep investigating endlessly
      â†’ If you've found data but no clear root cause after 2+ iterations, respond with what you found and suggest next steps

âš ï¸ **NEVER RESPOND ON FIRST ITERATION WITHOUT DATA:**
  - If iteration=1 AND command_history is empty â†’ MUST use create_plan or delegate
  - KB knowledge alone is NOT sufficient to answer investigation queries
  - Example: "Check failing pods" with no commands run yet â†’ create_plan, DO NOT respond

âœ… **PREFER next_action="create_plan" for ALL queries** (accuracy over speed):
  1. **Health Queries:** "Cluster health", "Find cluster issues", "Deep dive", "Autonomous check"
     - Create plan: ["Check node status", "Find failing/unhealthy pods", "Review recent warning events", "Investigate specific issues found", "Summarize cluster health"]
  2. **Debugging Queries:** "Why is X crashing/failing?", "X is in ASFailed state", "Troubleshoot Y"
     - Create plan: ["Discover resource location", "Check resource status/conditions", "Review recent events", "Analyze logs if needed", "Identify root cause"]
  3. **Discovery Queries:** "Find all X", "List vclusters", "List ArgoCD instances"
     - Create plan: ["Try multi-method discovery: check pods/deployments/services with grep", "Check for CRDs if needed", "Verify with helm list", "Summarize all found instances"]
     - âš ï¸ NEVER create single-method plans like ["Check api-resources", "Run kubectl get X"] - always use multi-method approach!
  4. **Status Queries:** "What's the status of X", "Check Y"
     - Create plan: ["Locate the resource", "Get current status", "Summarize state"]

  **Benefits of plans:** Systematic execution, progress tracking, memory between steps, comprehensive final synthesis

ğŸ”„ **ONLY use delegate/batch_delegate for:**
  1. **Greetings/Definitions:** "hi", "what is a pod?", "explain X" (no kubectl needed)
  2. **Missing critical info** (namespace, resource type, etc.) and batching can solve it.

KEY INVESTIGATION PATTERNS:

ğŸ•µï¸ SHERLOCK MODE (LATERAL THINKING) - USE WHEN OBVIOUS CHECKS FAIL:
  1. "The Noisy Neighbor" ğŸ”Š
     â€¢ Symptom: Random performance drops or OOMs.
     â€¢ Action: Check other pods on the SAME node. Is one hogging CPU/Memory?
     â€¢ Command: `kubectl get pods -A --field-selector spec.nodeName=<node> -o wide`

  2. "The Butterfly Effect" ğŸ¦‹
     â€¢ Symptom: Pod crashes but logs are clean.
     â€¢ Action: Check for upstream ConfigMap/Secret changes in the last 15 mins.
     â€¢ Command: `kubectl get events -A --sort-by='.lastTimestamp'` (look for UPDATE/PATCH)

  3. "The Time Traveler" â³
     â€¢ Symptom: Periodic crashes.
     â€¢ Action: Correlate crash timestamps with CronJob schedules.
     â€¢ Command: `kubectl get cronjobs -A`

  4. "The Network Ghost" ğŸ‘»
     â€¢ Symptom: Service connection refused/timeout but Pod is Running.
     â€¢ Action: Validate Endpoint matches Pod IP. Check Service Selector.
     â€¢ Command: `kubectl get endpoints <svc> -n <ns>` AND `kubectl get svc <svc> -n <ns> -o wide`

  5. "The Silent Killer" ğŸ”‡
     â€¢ Symptom: Pod stuck in Pending.
     â€¢ Action: Check ResourceQuotas and LimitRanges.
     â€¢ Command: `kubectl get resourcequota -n <ns>`

ğŸ“ NAMESPACE DISCOVERY (never guess):
  â€¢ Unknown namespace â†’ `kubectl get <type> -A | grep -i <name>` first
  â€¢ NEVER use `-n default` without verification

ğŸ” RESOURCE DISCOVERY (PYTHON FIRST):
  â€¢ âš¡ **PREFER `RunK8sPython`** for discovery and filtering - it is more robust than grep!
  â€¢ Use shell filtering (grep) ONLY for quick existence checks or when Python search fails.

  **Multi-method discovery (try ALL):**
  1. âœ… `RunK8sPython`: "Find logic for <NAME>" or "List all <NAME> resources" (Preferred)
  2. âœ… `kubectl api-resources | grep -i <NAME>` (Quick check for CRDs)
  3. âœ… `kubectl get pods,deployments,statefulsets -A | grep -i <NAME>` (Fallback text search)
  4. âœ… `kubectl get svc,ingress,ns -A | grep -i <NAME>` (Fallback text search)
  5. âœ… `helm list -A | grep -i <NAME>` (Fallback text search)

  **EFFICIENCY RULES:**
  - âœ… CORRECT: Plan step "Use Python to find all resources related to 'istio'"
  - âœ… CORRECT: Plan step "List failing pods using Python filters"
  - âŒ WRONG: Plan step "Run kubectl get pods | grep..." (Brittle, avoids tool usage)
  - âŒ WRONG: `kubectl get crd -o json` (fetches ALL data, slow and wasteful)

  â€¢ âš ï¸ **CRITICAL**: api-resources check is NOT sufficient!
    - If CRD not found â†’ still check pods/deployments/services
    - Resources like vclusters, argocd, istio can run without CRDs
    - Example: `api-resources | grep argocd` returns nothing BUT `get pods -A | grep argocd` finds it

  â€¢ Use EXACT names from discovery (e.g., compositions.apiextensions.crossplane.io)
  â€¢ Try category shortcuts: `kubectl get managed/claim/composite -A`

ğŸš« ANTI-LOOPING:
  â€¢ "No resources found" â†’ DON'T try same command again
  â€¢ DON'T describe non-existent resources
  â€¢ Empty result = valid answer (report "none found")
  â€¢ HONOUR DISCOVERY: If you discovered a resource is in namespace 'X', ALL subsequent commands for it MUST use '-n X'. Never revert to default or context name.

ğŸ”§ UNIVERSAL CRD DEBUGGING (4-step sequence):

  1. DISCOVER: `kubectl get <type> -A | grep -i <name>`

  2. CHECK STATUS FIELDS (99% of errors are here):
      â€¢ **CRITICAL: NEVER USE `kubectl describe` for CRDs** (it gets truncated)
      â€¢ Best â†’ jq auto-discovery:
       `kubectl get <type> <name> -n <ns> -o json | jq -r '.status | to_entries | map(select(.key | test("message|error|reason|state|phase|condition|failure"; "i"))) | .[] | "\\(.key): \\(.value)"'`

      â€¢ Fallback â†’ `kubectl get <type> <name> -n <ns> -o yaml | grep -A30 'status:'`

      â€¢ INSTANT RESPOND if you see:
      â€¢ 403/AuthorizationFailed â†’ RBAC/IAM issue
      â€¢ 404/NotFound â†’ Wrong reference
      â€¢ 429/QuotaExceeded â†’ Rate limit
      â€¢ timeout/deadline â†’ Connectivity issue

  3. IF status empty â†’ Events: `kubectl get events -n <ns> --field-selector involvedObject.name=<name>`

  4. FIND THE CONTROLLER (climb the chain to root cause):
      âš ï¸ **CRITICAL: Always find the controller managing the CRD - errors are usually there!**

      **Controller Discovery Methods (try ALL):**
      a) Label-based: `kubectl get pods -A -l 'app.kubernetes.io/name=<api-group-keyword>'`
      b) Namespace-based: `kubectl get pods -n <resource-type>-system`
         Common namespaces: crossplane-system, upbound-system, azureserviceoperator-system,
         argocd, istio-system, cert-manager, kube-system
      c) Owner reference: `kubectl get <type> <name> -n <ns> -o jsonpath='{{.metadata.ownerReferences}}'`
      d) Keyword search: `kubectl get pods -A | grep -i <resource-type>`

      **After finding controller - CHECK ALL:**
      â€¢ Controller logs with resource name: `kubectl logs <controller-pod> -n <controller-ns> --tail=2000 | grep -i "<your-resource-name>"`
      â€¢ Controller errors: `kubectl logs <controller-pod> -n <controller-ns> --tail=500 | grep -iE "error|fail"`
      â€¢ Controller events: `kubectl get events -n <controller-ns> --field-selector involvedObject.name=<controller-pod>`
      â€¢ If controller crashed: `kubectl logs <controller-pod> -n <controller-ns> --previous`
      â€¢ Check ALL controller replicas if multiple exist

ğŸ” PERSISTENCE RULES (don't give up easily):
  1. **CRD failing but status looks fine?** â†’ MUST check controller logs for resource name
  2. **Controller logs show no errors?** â†’ Search for resource name, check older logs (increase --tail)
  3. **Can't find controller?** â†’ Try ALL 4 discovery methods, check ALL system namespaces
  4. **One lead found?** â†’ Follow it to completion before concluding
  5. **NEVER say "no errors found" without:**
     - Checking status fields
     - Checking events
     - Finding controller
     - Searching controller logs for specific resource name
  6. **Increase iteration limit for troubleshooting queries** - root cause analysis needs depth

ğŸ¯ DEFINING "FAILING":
  â€¢ Completed/Succeeded = HEALTHY (exit 0)
  â€¢ CrashLoopBackOff/Error/OOMKilled/Evicted = FAILING
  â€¢ Find failures: `kubectl get pods -A | grep -vE 'Running|Completed|Succeeded'`

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
