

import { useState, useEffect, useRef, useCallback, useMemo } from 'react';
import { createPortal } from 'react-dom';
import { Loader2, Send, Sparkles, X, Minimize2, Maximize2, Minus, Settings, ChevronDown, AlertCircle, StopCircle, RefreshCw, Terminal, CheckCircle2, XCircle, Trash2 } from 'lucide-react';
import { invoke } from '@tauri-apps/api/core';
import { listen, emit, UnlistenFn } from '@tauri-apps/api/event';
import ReactMarkdown from 'react-markdown';
import { ToolMessage } from './chat/ToolMessage';
import { ThinkingMessage } from './chat/ThinkingMessage';
import { InvestigationTimeline } from './chat/InvestigationTimeline';
import { StreamingProgressCard, AgentPhase, CommandExecution } from './chat/StreamingProgressCard';
import remarkGfm from 'remark-gfm';
import { LLMConfig, LLMStatus, ClusterHealthSummary } from '../../types/ai';
import { fixMarkdownHeaders } from '../../utils/markdown';
import { stripAnsi } from '../../utils/ansi';
import { loadLLMConfig } from './utils';
import { LLMSettingsPanel } from './LLMSettingsPanel';
import { OllamaSetupInstructions } from './OllamaSetupInstructions';
import {
    executeTool, VALID_TOOLS, registerMcpTools, isValidTool, listRegisteredMcpTools
} from './tools';
import {
    ToolOutcome, PlanStep, InvestigationPlan,
    ResourceDiscoveryCache, DEFAULT_ITERATION_CONFIG, isEmptyResult, compressToolHistorySemantic
} from './types';
import {
    extractCommandsFromResponse,
    extractSuggestions,
    extractLearningMetadata,
    recordInvestigationForLearning,
} from './agentUtils';

import { runAgentLoop, AgentStep, LLMOptions } from './agentOrchestrator';
import { PlanProgressUI } from './PlanProgressUI';
import { formatFailingPods } from './kubernetesFormatter';
import { KBProgress } from './useSentinel';
import { ClaudeCodePanel } from './ClaudeCodePanel';

// ... (Known MCP Servers constant omitted for brevity, it is unchanged)
const KNOWN_MCP_SERVERS = [
    { name: 'azure-devops', command: 'npx', args: ['-y', '@azure-devops/mcp', 'YOUR_ORG_NAME'], env: {}, connected: false, autoConnect: false },
    { name: 'kubernetes', command: 'uvx', args: ['mcp-server-kubernetes'], env: { KUBECONFIG: '~/.kube/config' }, autoConnect: false },
    { name: 'github', command: 'npx', args: ['-y', '@modelcontextprotocol/server-github'], env: { GITHUB_TOKEN: '...' }, autoConnect: false },
    { name: 'gitlab', command: 'npx', args: ['-y', '@modelcontextprotocol/server-gitlab'], env: { GITLAB_TOKEN: '...', GITLAB_API_URL: 'https://gitlab.com/api/v4' }, autoConnect: false },
    { name: 'git', command: 'uvx', args: ['mcp-server-git'], env: {}, autoConnect: true },
    { name: 'slack', command: 'npx', args: ['-y', '@modelcontextprotocol/server-slack'], env: { SLACK_BOT_TOKEN: '...' }, autoConnect: false },
    { name: 'gcp', command: 'uvx', args: ['gcp-mcp-server'], env: { GOOGLE_APPLICATION_CREDENTIALS: '~/.config/gcloud/application_default_credentials.json' }, autoConnect: false },
    { name: 'postgres', command: 'uvx', args: ['mcp-server-postgres', 'postgresql://user:pass@host:5432/db'], env: {}, autoConnect: false },
    { name: 'sqlite', command: 'uvx', args: ['mcp-server-sqlite', '--db-path', 'test.db'], env: {}, autoConnect: false },
    { name: 'time', command: 'uvx', args: ['mcp-server-time'], env: {}, autoConnect: true },
    // Shell MCP server for bash/shell command execution - secure with directory restrictions
    { name: 'shell', command: 'uvx', args: ['mcp-shell-server'], env: {}, autoConnect: false },
];

// Claude Code stream event type
interface ClaudeCodeStreamEvent {
    stream_id: string;
    event_type: 'start' | 'chunk' | 'done' | 'error' | 'progress';
    content: string;
}

// Helper to group messages into interactions
function groupMessages(history: any[]) {
    const groups: any[] = [];
    let currentGroup: any = null;

    // Filter function to hide verbose internal reasoning
    const shouldShowAsStep = (msg: any) => {
        // Always show tool executions (actual commands)
        if (msg.role === 'tool') return true;

        // For assistant messages, filter out internal reasoning
        if (msg.role === 'assistant') {
            const content = msg.content || '';
            // Hide verbose internal states
            if (content.includes('PLANNING:') ||
                content.includes('EXECUTING:') ||
                content.includes('REASONING CHAIN') ||
                content.includes('DONE') ||
                content.includes('VERIFIED:') ||
                content.includes('CONTINUE:') ||
                content.includes('SOLVED:') ||
                content.includes('WARN')) {
                return false;
            }
            // Show meaningful thinking/investigation messages
            return msg.isActivity ||
                content.includes('üß† Thinking') ||
                content.includes('üß† Supervisor') ||
                content.includes('üîÑ Investigating') ||
                content.includes('Continuing investigation');
        }
        return false;
    };

    history.forEach((msg) => {
        if (msg.role === 'user') {
            if (currentGroup) groups.push(currentGroup);
            currentGroup = { type: 'interaction', user: msg, steps: [], answer: null };
        } else if (shouldShowAsStep(msg)) {
            if (currentGroup) {
                currentGroup.steps.push(msg);
            } else {
                if (groups.length === 0 || groups[groups.length - 1].type !== 'system_steps') {
                    groups.push({ type: 'system_steps', steps: [msg] });
                } else {
                    groups[groups.length - 1].steps.push(msg);
                }
            }
        } else if (msg.role === 'assistant') {
            if (currentGroup && !currentGroup.answer) {
                currentGroup.answer = msg;
            } else {
                groups.push({ type: 'raw', msg });
            }
        } else {
            groups.push({ type: 'raw', msg });
        }
    });

    if (currentGroup) groups.push(currentGroup);
    return groups;
}

// Cluster-wide AI Chat Panel component - Global floating chat
export function ClusterChatPanel({
    onClose,
    isMinimized,
    onToggleMinimize,
    currentContext,
    embedded = false,
    resourceContext,
    initialPrompt,
    onPromptHandled,
    kbProgress
}: {
    onClose?: () => void,
    isMinimized?: boolean,
    onToggleMinimize?: () => void,
    currentContext?: string,
    embedded?: boolean,
    resourceContext?: { kind: string; name: string; namespace: string },
    initialPrompt?: string | null,
    onPromptHandled?: () => void,
    kbProgress?: KBProgress | null
}) {
    const messagesContainerRef = useRef<HTMLDivElement>(null);

    // Trigger auto-investigation if initialPrompt is provided
    useEffect(() => {
        if (initialPrompt && !userInput && !llmLoading) {
            // Wait briefly for mount
            setTimeout(() => {
                sendMessage(initialPrompt);
                if (onPromptHandled) onPromptHandled();
            }, 100);
        }
    }, [initialPrompt]);

    // Unique storage key for resource-specific chats
    const storageKey = resourceContext
        ? `ops - pilot - chat - ${resourceContext.namespace} -${resourceContext.kind} -${resourceContext.name} `
        : 'ops-pilot-chat-history';

    const [chatHistory, setChatHistory] = useState<Array<{ role: 'user' | 'assistant' | 'tool' | 'claude-code', content: string, toolName?: string, command?: string, isActivity?: boolean, isStreaming?: boolean }>>(() => {
        try {
            const saved = localStorage.getItem(storageKey);
            if (!saved) return [];
            const parsed = JSON.parse(saved);
            // Sanitize history: ensure no message is stuck in 'streaming' state on reload
            return parsed.map((msg: any) => ({ ...msg, isStreaming: false }));
        } catch (e) {
            console.warn('Failed to load chat history:', e);
            return [];
        }
    });
    const [userInput, setUserInput] = useState("");

    // Group messages for better UI presentation (timeline)
    const groupedHistory = useMemo(() => groupMessages(chatHistory), [chatHistory]);

    const [llmLoading, setLlmLoading] = useState(false);
    const [currentActivity, setCurrentActivity] = useState("Analyzing cluster data...");
    const [isExpanded, setIsExpanded] = useState(false);
    const [llmConfig, setLlmConfig] = useState<LLMConfig>(loadLLMConfig);
    const [llmStatus, setLlmStatus] = useState<LLMStatus | null>(null);
    const [checkingLLM, setCheckingLLM] = useState(true);
    const [showSettings, setShowSettings] = useState(false);
    const [suggestedActions, setSuggestedActions] = useState<string[]>([]);

    // Chat State managed above (chatHistory)
    const [investigationPlan, setInvestigationPlan] = useState<InvestigationPlan | null>(null);

    // Persistent Session Thread ID
    const [threadId, setThreadId] = useState<string>(() => {
        const saved = localStorage.getItem('agent_thread_id');
        // Check if crypto global is available (browser context)
        if (typeof crypto !== 'undefined' && crypto.randomUUID) {
            return saved || crypto.randomUUID();
        }
        return saved || 'session-' + Math.random().toString(36).substr(2, 9);
    });

    // Save thread_id to ensure persistence across reloads
    useEffect(() => {
        if (threadId) {
            localStorage.setItem('agent_thread_id', threadId);
        }
    }, [threadId]);

    const handleClearHistory = useCallback(() => {
        setChatHistory([]);
        setInvestigationPlan(null);
        setInvestigationProgress(null);
        setPhaseTimeline([]);
        setRankedHypotheses([]);
        setApprovalContext(null);
        setGoalVerification(null);
        setExtendedMode(null);

        // Rotate thread_id
        let newThreadId = '';
        if (typeof crypto !== 'undefined' && crypto.randomUUID) {
            newThreadId = crypto.randomUUID();
        } else {
            newThreadId = 'session-' + Math.random().toString(36).substr(2, 9);
        }
        setThreadId(newThreadId);
        localStorage.setItem('agent_thread_id', newThreadId);
    }, []);
    const chatEndRef = useRef<HTMLDivElement>(null);

    // Claude Code streaming state
    const [streamingContent, setStreamingContent] = useState<string>("");
    const [isStreaming, setIsStreaming] = useState(false);
    const [currentStreamId, setCurrentStreamId] = useState<string | null>(null);
    const streamUnlistenRef = useRef<UnlistenFn | null>(null);

    // Embedding model status (for knowledge base)
    const [embeddingStatus, setEmbeddingStatus] = useState<'loading' | 'ready' | 'error' | null>(null);
    const [embeddingMessage, setEmbeddingMessage] = useState<string>('');

    // Cancel/abort controller for long-running requests
    const abortControllerRef = useRef<AbortController | null>(null);
    const [isCancelling, setIsCancelling] = useState(false);

    // Investigation chain-of-thought state (visible to user)
    const [investigationProgress, setInvestigationProgress] = useState<{
        iteration: number;
        maxIterations: number;
        phase: string;
        confidence: { level: string; score: number };
        hypotheses: Array<{ id: string; description: string; status: string }>;
        toolsExecuted: number;
        usefulEvidence: number;
    } | null>(null);

    // Welcome joke fetched from LLM
    const [welcomeJoke, setWelcomeJoke] = useState<string | null>(null);
    const [loadingWelcomeJoke, setLoadingWelcomeJoke] = useState(false);

    // Hardware Specs
    const [systemSpecs, setSystemSpecs] = useState<{ cpu_brand: string; total_memory: number; is_apple_silicon: boolean; } | null>(null);

    // Model Download Progress State
    const [downloadProgress, setDownloadProgress] = useState<{ status: string; percent?: number; completed?: number; total?: number } | null>(null);
    const [showDownloadConfirm, setShowDownloadConfirm] = useState(false);

    // Plan execution state (ReAct pattern)
    const [currentPlan, setCurrentPlan] = useState<any[] | null>(null);

    // Streaming progress state for StreamingProgressCard
    const [streamingPhase, setStreamingPhase] = useState<AgentPhase | null>(null);
    const commandHistoryRef = useRef<CommandExecution[]>([]);
    const [planTotalSteps, setPlanTotalSteps] = useState<number>(0);

    // New enriched investigation signals from backend
    const [phaseTimeline, setPhaseTimeline] = useState<Array<{ name: string; timestamp?: string }>>([]);
    const [rankedHypotheses, setRankedHypotheses] = useState<Array<{ title: string; confidence?: number }>>([]);
    const [approvalContext, setApprovalContext] = useState<{ command?: string; reason?: string; risk?: string; impact?: string } | null>(null);
    const [coverageGaps, setCoverageGaps] = useState<Array<string>>([]);
    const [agentHints, setAgentHints] = useState<Array<string>>([]);
    const [goalVerification, setGoalVerification] = useState<{ met: boolean; reason: string } | null>(null);
    const [autoExtendEnabled, setAutoExtendEnabled] = useState<boolean>(true);
    const [extendedMode, setExtendedMode] = useState<{ preferred_checks?: string[]; prefer_mcp_tools?: boolean } | null>(null);

    // Check LLM status and fetch MCP tools on mount
    useEffect(() => {
        checkLLMStatus();
        fetchMcpTools();
    }, [llmConfig]); // eslint-disable-line react-hooks/exhaustive-deps

    // Initialize embedding model and listen for status events
    // ... (Embedding useEffect unchanged)
    useEffect(() => {
        let unlistenFn: UnlistenFn | null = null;
        const setupEmbeddingListener = async () => {
            // ... (existing logic) ...
        };
        // For brevity in this replacement, we assume the existing logic is preserved if we don't touch it.
        // Wait, I am replacing the WHOLE file content from line 1 to 2179 ???
        // NO, the tool description says "The output of this tool call will be the file contents from StartLine to EndLine (inclusive)".
        // But `replace_file_content` replaces a contiguous block.
        // So I must provide the *exact* original content for `TargetContent`.
        // The file is huge. Simple replace is risky if I don't have exact content match.
        // I should use `multi_replace_file_content` or `replace_file_content` on a smaller chunk.
        // The instruction was "Replace global agent:terminal:data listener".
        // The original listener is around lines 358-400.
    }, []);

    // ... (rest of the file)


    // Function to fetch a welcome dad joke from the LLM
    const fetchNewWelcomeJoke = useCallback(async () => {
        if (loadingWelcomeJoke) return;
        setLoadingWelcomeJoke(true);
        try {
            const response = await invoke<string>('llm_chat', {
                messages: [{
                    role: 'user',
                    content: 'Generate ONE short, funny dad joke about Kubernetes, containers, DevOps, or programming. Just the joke itself, no introduction or explanation. Keep it under 100 characters. Include one relevant emoji. Be creative and different each time!'
                }],
                config: llmConfig,
                systemPrompt: 'You are a witty DevOps engineer who loves dad jokes. Respond with ONLY the joke, nothing else. Never repeat the same joke twice.',
                maxTokens: 100,
                thread_id: threadId, // Pass the persistent thread ID
            });
            setWelcomeJoke(response.trim());
        } catch (err) {
            console.warn('Failed to fetch welcome joke:', err);
            // Fallback to a static joke
            const fallbacks = [
                "Why do Kubernetes pods make terrible comedians? Their jokes keep crashing! üé§",
                "Why do programmers prefer dark mode? Because light attracts bugs! üêõ",
                "What's a pod's favorite dance? The crash loop shuffle! üíÉ",
                "Why did the container go to therapy? It had too many issues with its parent image! üê≥",
                "What do you call a Kubernetes cluster with trust issues? A secret manager! ü§´",
            ];
            setWelcomeJoke(fallbacks[Math.floor(Math.random() * fallbacks.length)]);
        }
        setLoadingWelcomeJoke(false);
    }, [llmConfig, loadingWelcomeJoke, threadId]);

    // Auto-scroll to bottom when chat updates
    const scrollToBottom = () => {
        if (messagesContainerRef.current) {
            const { scrollHeight, clientHeight } = messagesContainerRef.current;
            messagesContainerRef.current.scrollTo({
                top: scrollHeight - clientHeight,
                behavior: 'smooth'
            });
        }
    };

    useEffect(() => {
        scrollToBottom();
    }, [chatHistory, currentActivity, investigationProgress, llmLoading, streamingContent, embeddingMessage]);

    // Persist chat history
    useEffect(() => {
        try {
            // Compress highly redundant history before saving if needed, but for now just save
            // Limit to last 50 messages to avoid quota limits
            const historyToSave = chatHistory.slice(-50);
            localStorage.setItem(storageKey, JSON.stringify(historyToSave));
        } catch (e) {
            console.warn('Failed to save chat history:', e);
        }
    }, [chatHistory, storageKey]);

    // Fetch welcome joke when LLM becomes connected
    useEffect(() => {
        if (llmStatus?.connected && !welcomeJoke && !loadingWelcomeJoke && chatHistory.length === 0) {
            fetchNewWelcomeJoke();
        }
    }, [llmStatus?.connected, welcomeJoke, loadingWelcomeJoke, chatHistory.length, fetchNewWelcomeJoke]);

    // Auto-add well-known MCP servers (Azure, Azure DevOps, Kubernetes, GCP, GitHub) and connect if available
    useEffect(() => {
        const saved = localStorage.getItem('opspilot-mcp-servers');
        let servers: any[] = [];
        try {
            servers = saved ? JSON.parse(saved) : [];
        } catch (err) {
            console.warn("Failed to parse saved MCP servers", err);
        }

        // Merge with defaults, preferring saved config but REPAIRING broken package names
        const merged = KNOWN_MCP_SERVERS.map(known => {
            const saved = servers.find((s: any) => s.name === known.name);
            if (saved) {
                // STRICT SAFETY: Force disable auto-connect for interactive/cloud services
                // This ensures they never auto-start without explicit user action, regardless of past config
                const isInteractive = ['github', 'gitlab', 'azure-devops', 'slack', 'gcp', 'postgres'].includes(known.name);
                const safeAutoConnect = isInteractive ? false : (saved.autoConnect !== undefined ? saved.autoConnect : known.autoConnect);

                let updated = { ...saved, autoConnect: safeAutoConnect };

                // AUTO-REPAIR: Fix broken package names or commands

                // Fix: Auto-migrate Node.js based servers to use 'npx'
                if (['github', 'slack', 'gitlab'].includes(known.name) && saved.command === 'uvx') {
                    console.log(`[MCP] Migrating ${known.name} to npx packaged version`);
                    updated = { ...updated, command: known.command, args: known.args };
                }

                // Fix: Migrate legacy Azure DevOps to official Microsoft package
                if (updated.name === 'azure-devops' && (updated.args.join(' ').includes('ryancardin') || updated.command === 'uvx')) {
                    console.log(`[MCP] Migrating Azure DevOps to official Microsoft package`);
                    // We attempt to preserve the org if it was in the env, otherwise default
                    const oldOrg = updated.env?.AZURE_DEVOPS_ORG || '';
                    const orgName = oldOrg.split('/').pop() || 'YOUR_ORG_NAME'; // rough heuristic extracting 'yourorg' from url
                    updated = { ...updated, command: 'npx', args: ['-y', '@azure-devops/mcp', orgName], env: {} }; // Clear env as it's interactive auth or different
                }

                // Fix: Legacy GCP package name
                if (updated.args && updated.args[0] === 'mcp-server-gcp') {
                    updated = { ...updated, args: ['gcp-mcp-server', ...updated.args.slice(1)] };
                }

                // Fix: Ensure SQLite has correct args if missing
                if (updated.name === 'sqlite' && (!updated.args || !updated.args.includes('--db-path'))) {
                    updated = { ...updated, args: known.args };
                }

                return updated;
            }
            return known;
        }).concat(servers.filter((s: any) => !KNOWN_MCP_SERVERS.find(k => k.name === s.name)));

        // Filter out completely invalid/non-existent packages that might have been added
        const cleaned = merged.filter((s: any) => {
            // Purge known broken/legacy implementations that cause startup crashes
            if (['redis', 'mysql', 'snowflake', 'aws', 'azure'].includes(s.name)) {
                console.warn(`[MCP] Removing legacy / broken server config: ${s.name} `);
                return false;
            }
            // Ensure 'azure-devops' is the correct one
            if (s.name === 'azure-devops' && s.args && s.args[0] === 'mcp-server-azure-devops') return false;

            return true;
        });

        const preflightAndConnect = async () => {
            // Check for uvx (always valid for python servers)
            try {
                await invoke('check_command_exists', { command: 'uvx' });
            } catch (err) {
                console.warn('[MCP] uvx not available.', err);
            }
            // Check for npx (for Node servers like github)
            try {
                await invoke('check_command_exists', { command: 'npx' });
            } catch (err) {
                console.warn('[MCP] npx not available.', err);
            }

            // Save the repaired config back to storage if we changed anything effectively
            if (JSON.stringify(cleaned) !== JSON.stringify(servers)) {
                localStorage.setItem('opspilot-mcp-servers', JSON.stringify(cleaned));
            }

            // Connect to servers sequentially (await each connection properly)
            const serversToConnect = cleaned.filter((s: any) => {
                const fullCmdString = `${s.command} ${(s.args || []).join(' ')} `.toLowerCase();
                if (fullCmdString.includes('calc') || fullCmdString.includes('calculator') || s.command === 'open') {
                    console.warn(`[MCP] Purging unsafe command from config: ${s.command} ${(s.args || []).join(' ')} `);
                    return false;
                }
                return s.autoConnect;
            });

            let connectedCount = 0;
            for (const s of serversToConnect) {
                try {
                    await invoke('connect_mcp_server', {
                        name: s.name,
                        command: s.command,
                        args: s.args,
                        env: s.env || {}
                    });
                    console.log(`[MCP] Auto - connected to ${s.name} `);
                    connectedCount++;
                } catch (err) {
                    console.warn(`[MCP] Auto - connect failed for ${s.name}: `, err);
                }
            }

            // Fetch MCP tools AFTER all connections are established
            if (connectedCount > 0) {
                console.log(`[MCP] Refreshing tools after ${connectedCount} server connections...`);
                try {
                    const tools = await invoke<any[]>("list_mcp_tools");
                    registerMcpTools(tools);
                    console.log(`[MCP] Loaded ${tools.length} tools from connected servers`);
                } catch (e) {
                    console.error("[MCP] Failed to refresh tools:", e);
                }
            }
        };

        preflightAndConnect();
    }, []);





    const fetchMcpTools = async () => {
        try {
            const tools = await invoke<any[]>("list_mcp_tools");
            registerMcpTools(tools);
        } catch (e) {
            console.error("Failed to list MCP tools:", e);
        }
    };

    const checkLLMStatus = async () => {
        setCheckingLLM(true);
        try {
            if (llmConfig.provider === 'claude-code') {
                const ccStatus = await invoke<{ available: boolean; version: string | null; error: string | null }>("check_claude_code_status");
                setLlmStatus({
                    connected: ccStatus.available,
                    provider: 'claude-code',
                    model: ccStatus.version || 'claude-code-cli',
                    available_models: [],
                    error: ccStatus.error,
                });
                setCheckingLLM(false);
            } else {
                let status = await invoke<LLMStatus>("check_llm_status", { config: llmConfig });

                // Check if connection is OK but model is missing
                if (llmConfig.provider === 'ollama' && status.connected && status.error?.includes('not found')) {
                    const isLocalhost = llmConfig.base_url.includes('localhost') || llmConfig.base_url.includes('127.0.0.1');

                    // Prioritize verifying if any other models exist on the remote server
                    if (!isLocalhost && status.available_models && status.available_models.length > 0) {
                        // REMOTE: Auto-fallback to first available model
                        // This prevents forcing a download on a remote server that might be read-only
                        const fallbackModel = status.available_models[0];
                        console.log(`[Auto - Heal] Remote server detected.Fallback to existing model: ${fallbackModel} `);

                        // Update config to use the available model
                        setLlmConfig(prev => ({ ...prev, model: fallbackModel }));
                        // The effect will reload status automatically.
                        // We return early to let the re-render handle the new status.
                        return;
                    } else if (isLocalhost) {
                        // LOCAL: Request confirmation to download
                        console.log('[Auto-Heal] Local model not found, requesting confirmation...');
                        setShowDownloadConfirm(true);
                        setCheckingLLM(false);
                    } else {
                        // Remote but NO models at all? Or remote but we can't switch? Show the error.
                        setLlmStatus(status);
                        setCheckingLLM(false);
                    }
                } else {
                    setLlmStatus(status);
                    setCheckingLLM(false);
                }
            }
        } catch (err) {
            setLlmStatus({
                connected: false,
                provider: llmConfig.provider,
                model: llmConfig.model,
                available_models: [],
                error: String(err),
            });
            setCheckingLLM(false);
        }
    };

    // Auto-scroll to bottom
    useEffect(() => {
        if (chatEndRef.current) {
            chatEndRef.current.scrollIntoView({ behavior: 'smooth', block: 'nearest' });
        }
    }, [chatHistory]);

    // Get a user-friendly description of what the tool does
    const getToolActivity = (toolName: string, args?: string): string => {
        const toolDescriptions: Record<string, string> = {
            'CLUSTER_HEALTH': 'üîç Checking cluster health...',
            'GET_EVENTS': args ? `üìã Fetching events for ${args}...` : 'üìã Fetching cluster events...',
            'LIST_ALL': args ? `üìä Listing ${args} resources...` : 'üìä Listing resources...',
            'DESCRIBE': args ? `üî¨ Describing ${args}...` : 'üî¨ Getting resource details...',
            'GET_LOGS': args ? `üìú Fetching logs for ${args}...` : 'üìú Fetching pod logs...',
            'TOP_PODS': args ? `üìà Checking pod metrics in ${args}...` : 'üìà Checking pod resource usage...',
            'FIND_ISSUES': 'üîé Scanning for cluster issues...',
            'SEARCH_KNOWLEDGE': args ? `üìö Searching knowledge base for "${args}"...` : 'üìö Searching knowledge base...',
            'GET_ENDPOINTS': args ? `üåê Getting endpoints for ${args}...` : 'üåê Getting service endpoints...',
            'GET_NAMESPACE': args ? `üìÅ Inspecting namespace $ { args }...` : 'üìÅ Inspecting namespace...',
            'LIST_FINALIZERS': args ? `üîó Finding finalizers in ${args}...` : 'üîó Finding stuck finalizers...',
        };
        return toolDescriptions[toolName] || `‚öôÔ∏è Executing ${toolName}...`;
    };

    // NOTE: Knowledge base search is now triggered BY THE LLM when it decides it's needed
    // via the SEARCH_KNOWLEDGE tool. No automatic pre-search - LLM is the intelligent orchestrator.


    // Helper to call LLM - routes to Claude Code CLI or regular API
    const callLLM = async (
        prompt: string,
        systemPrompt: string,
        conversationHistory: Array<{ role: string; content: string }>,
        options?: LLMOptions
    ): Promise<string> => {
        if (llmConfig.provider === 'claude-code') {
            // Build conversation context for Claude Code
            const historyStr = conversationHistory
                .slice(-10) // Last 10 messages for context
                .map(m => `${m.role.toUpperCase()}: ${m.content} `)
                .join('\n\n');

            const fullPrompt = historyStr ? `${historyStr} \n\nUSER: ${prompt} ` : prompt;

            return await invoke<string>("call_claude_code", {
                prompt: fullPrompt,
                systemPrompt,
            });
        } else {
            // Merge options with config (options override config values)
            const configWithOptions = options ? {
                ...llmConfig,
                temperature: options.temperature ?? llmConfig.temperature,
                max_tokens: options.max_tokens ?? llmConfig.max_tokens,
                model: options.model ?? llmConfig.model,
            } : llmConfig;

            return await invoke<string>("call_llm", {
                config: configWithOptions,
                prompt,
                systemPrompt,
                conversationHistory,
                thread_id: threadId, // Pass the persistent thread ID
            });
        }
    };



    // Cancel ongoing analysis
    const cancelAnalysis = useCallback(() => {
        setIsCancelling(true);
        if (abortControllerRef.current) {
            abortControllerRef.current.abort();
        }
        // Add cancellation message to chat
        setChatHistory(prev => [...prev, {
            role: 'assistant',
            content: '‚ö†Ô∏è Analysis cancelled by user.'
        }]);
        setLlmLoading(false);
        setIsCancelling(false);
        setCurrentActivity("");
    }, []);

    // Helper to generate human-readable command summaries
    const generateCommandSummary = (command: string, output: string): string => {
        if (!output || output.trim() === '') return 'No output';

        const lines = output.split('\n').filter(l => l.trim());

        // Count resources for kubectl get commands
        if (command.includes('get')) {
            const dataLines = lines.filter(l =>
                !l.startsWith('NAME') &&
                !l.startsWith('NAMESPACE') &&
                !l.startsWith('No resources') &&
                l.trim() !== ''
            );
            if (dataLines.length > 0) {
                return `Found ${dataLines.length} resource(s)`;
            }
            if (output.includes('No resources found')) {
                return 'No resources found';
            }
        }

        // Look for errors
        if (output.toLowerCase().includes('error') || output.toLowerCase().includes('failed')) {
            return 'Command failed - see raw output';
        }

        // Look for CrashLoopBackOff
        if (output.includes('CrashLoopBackOff')) {
            const count = (output.match(/CrashLoopBackOff/g) || []).length;
            return `Found ${count} pod(s) in CrashLoopBackOff`;
        }

        // Default: first non-empty line (truncated)
        const firstLine = lines[0];
        return firstLine ? firstLine.substring(0, 80) + (firstLine.length > 80 ? '...' : '') : 'Command executed';
    };

    const sendMessage = async (message: string) => {
        if (!message.trim() || llmLoading) return;

        // Create new abort controller for this request
        abortControllerRef.current = new AbortController();

        setChatHistory(prev => [...prev, { role: 'user', content: message }]);
        setUserInput("");
        setLlmLoading(true);
        setSuggestedActions([]);

        // Claude Code mode uses the local terminal instead
        if (llmConfig.provider === 'claude-code') {
            // Don't process messages here - user should use the terminal
            setLlmLoading(false);
            return;
        }

        // ===== HIERARCHICAL SUPERVISOR-WORKER AGENT =====
        // Replaces the old single-loop logic with the Orchestrator
        // See: agentOrchestrator.ts for the Supervisor/Scout/Specialist logic
        try {
            setCurrentActivity("üöÄ Initializing Supervisor Agent...");

            // Initialize streaming progress UI
            commandHistoryRef.current = [];
            setStreamingPhase({
                phase: 'planning',
                message: 'Creating investigation plan...',
                commandHistory: []
            });

            // Create abort controller for this request
            const controller = new AbortController();
            abortControllerRef.current = controller;

            // Convert RECENT chat history to agent context (only last 3 messages for follow-up context)
            // Each new question starts mostly fresh - don't carry over old investigations
            const contextHistory: AgentStep[] = chatHistory
                .filter(m => m.role === 'user' || m.role === 'assistant')
                .slice(-3) // Only last 3 messages for minimal context
                .map(m => ({
                    role: m.role === 'user' ? 'USER' as const :
                        m.role === 'tool' ? 'SCOUT' as const :
                            'SUPERVISOR' as const, // Map general assistant to Supervisor for context
                    content: m.content
                }));

            // Inject Resource Context if available
            if (resourceContext) {
                const resourceContextMsg = `CONTEXT LOCK: ACTIVE RESOURCE DEEP DIVE\n` +
                    `You are currently analyzing a specific resource in the Deep Dive Drawer: \n` +
                    `‚Ä¢ Kind: ${resourceContext.kind} \n` +
                    `‚Ä¢ Name: ${resourceContext.name} \n` +
                    `‚Ä¢ Namespace: ${resourceContext.namespace} \n\n` +
                    `CRITICAL INSTRUCTIONS: \n` +
                    `1. ALL user queries imply THIS specific resource unless explicitly stated otherwise.\n` +
                    `2. example: "why is it failing?" ‚Üí check logs / events for ${resourceContext.name}.\n` +
                    `3. example: "show logs" ‚Üí fetch logs for ${resourceContext.name}.\n` +
                    `4. DO NOT search for other pods or resources unless the user explicitly names them.\n` +
                    `5. If the user asks a general question, answer it in the context of ${resourceContext.name}.\n` +
                    `6. You are "immersed" in this resource.Do not broaden scope unnecessarily.`;

                // Prepend to context as a system-like USER instruction
                contextHistory.unshift({
                    role: 'USER',
                    content: resourceContextMsg
                });
            }

            // ===== HIERARCHICAL SUPERVISOR-WORKER AGENT =====
            // Replaces the old single-loop logic with the Orchestrator
            // See: agentOrchestrator.ts for the Supervisor/Scout/Specialist logic
            try {
                setCurrentActivity("üöÄ Initializing Supervisor Agent...");

                // Initialize streaming progress UI
                commandHistoryRef.current = [];
                setStreamingPhase({
                    phase: 'planning',
                    message: 'Creating investigation plan...',
                    commandHistory: []
                });

                // Create abort controller for this request
                const controller = new AbortController();
                abortControllerRef.current = controller;

                // Convert RECENT chat history to agent context (only last 3 messages for follow-up context)
                // Each new question starts mostly fresh - don't carry over old investigations
                const contextHistory: AgentStep[] = chatHistory
                    .filter(m => m.role === 'user' || m.role === 'assistant')
                    .slice(-3) // Only last 3 messages for minimal context
                    .map(m => ({
                        role: m.role === 'user' ? 'USER' as const :
                            m.role === 'tool' ? 'SCOUT' as const :
                                'SUPERVISOR' as const, // Map general assistant to Supervisor for context
                        content: m.content
                    }));

                // Inject Resource Context if available
                if (resourceContext) {
                    const resourceContextMsg = `CONTEXT LOCK: ACTIVE RESOURCE DEEP DIVE\n` +
                        `You are currently analyzing a specific resource in the Deep Dive Drawer: \n` +
                        `‚Ä¢ Kind: ${resourceContext.kind} \n` +
                        `‚Ä¢ Name: ${resourceContext.name} \n` +
                        `‚Ä¢ Namespace: ${resourceContext.namespace} \n\n` +
                        `CRITICAL INSTRUCTIONS: \n` +
                        `1. ALL user queries imply THIS specific resource unless explicitly stated otherwise.\n` +
                        `2. example: "why is it failing?" ‚Üí check logs / events for ${resourceContext.name}.\n` +
                        `3. example: "show logs" ‚Üí fetch logs for ${resourceContext.name}.\n` +
                        `4. DO NOT search for other pods or resources unless the user explicitly names them.\n` +
                        `5. If the user asks a general question, answer it in the context of ${resourceContext.name}.\n` +
                        `6. You are "immersed" in this resource.Do not broaden scope unnecessarily.`;

                    // Prepend to context as a system-like USER instruction
                    contextHistory.unshift({
                        role: 'USER',
                        content: resourceContextMsg
                    });
                }



                const result = await runAgentLoop(
                    // Current input
                    message.trim(),
                    // LLM Executor (Brain - Planner/Analyst)
                    // Options are passed from agentOrchestrator with role-specific temp/max_tokens
                    {
                        callLLM: async (prompt: string, systemPrompt: string, options: any) => {
                            return await invoke('call_llm', {
                                model: options?.model || 'opspilot-brain',
                                prompt,
                                systemPrompt,
                                temperature: options?.temperature || 0.7,
                                thread_id: threadId, // Pass the persistent thread ID
                            });
                        },
                        callLLMStream: async (prompt: string, systemPrompt: string, options: any) => {
                            return; // Stream not supported in this context yet
                        }
                    },
                    // Fast Executor (Muscle - Executor)
                    // Uses executor_model if configured, otherwise falls back to main model
                    async (prompt: string, systemPrompt: string, options: any) => {
                        if (llmConfig.executor_model) {
                            // Use the dedicated executor model for fast CLI translation
                            // Merge options with executor config
                            const executorConfig = {
                                ...llmConfig,
                                model: llmConfig.executor_model,
                                temperature: options?.temperature ?? llmConfig.temperature,
                                max_tokens: options?.max_tokens ?? llmConfig.max_tokens,
                            };
                            try {
                                return await invoke<string>("call_llm", {
                                    config: executorConfig,
                                    prompt,
                                    systemPrompt,
                                    conversationHistory: [],
                                    thread_id: threadId, // Pass the persistent thread ID
                                });
                            } catch (e) {
                                console.warn("Executor model failed, using Brain model:", e);
                                return await callLLM(prompt, systemPrompt, [], options);
                            }
                        }
                        // No executor_model configured - use the Brain model
                        return await callLLM(prompt, systemPrompt, [], options);
                    },
                    // Progress callback
                    (msg) => {
                        setCurrentActivity(msg);
                        // Capture backend suggestions emitted via orchestrator
                        if (msg.startsWith('[SUGGESTIONS]')) {
                            try {
                                const jsonStr = msg.replace('[SUGGESTIONS] ', '').trim();
                                const suggestions = JSON.parse(jsonStr);
                                if (Array.isArray(suggestions)) {
                                    setSuggestedActions(suggestions);
                                }
                            } catch (_) {
                                // ignore parse errors
                            }
                        }
                        // Update streaming phase based on progress message
                        const lowerMsg = msg.toLowerCase();
                        if (lowerMsg.includes('reasoning') || lowerMsg.includes('planning') || lowerMsg.includes('translating')) {
                            setStreamingPhase(prev => prev ? { ...prev, phase: 'planning', message: msg } : null);
                        } else if (lowerMsg.includes('analyzing') || lowerMsg.includes('reflecting') || lowerMsg.includes('investigating')) {
                            setStreamingPhase(prev => prev ? { ...prev, phase: 'analyzing', message: msg } : null);
                        } else if (lowerMsg.includes('executing') || lowerMsg.includes('running')) {
                            setStreamingPhase(prev => prev ? { ...prev, phase: 'executing', message: msg } : null);
                        }
                    },
                    // Streaming step callback
                    (step) => {
                        // Add intermediate steps to history so they appear in UI
                        let content = step.content;
                        // Map internal roles to user-friendly names
                        let toolName = step.role === 'SCOUT' ? 'Terminal' : step.role;

                        let command = undefined;

                        // Try to interpret structured backend event payloads
                        try {
                            const maybe = JSON.parse(step.content);
                            if (maybe && typeof maybe === 'object' && maybe.type) {
                                switch (maybe.type) {
                                    case 'phase': {
                                        const name = maybe.phase || maybe.name || 'phase';
                                        const timestamp = maybe.timestamp;
                                        setPhaseTimeline(prev => [...prev, { name, timestamp }]);
                                        setChatHistory(prev => [...prev, { role: 'assistant', content: `Phase: ${name}` }]);
                                        return; // handled
                                    }
                                    case 'hypotheses': {
                                        const list = Array.isArray(maybe.items) ? maybe.items : (Array.isArray(maybe.hypotheses) ? maybe.hypotheses : []);
                                        const normalized = list.map((h: any) => ({ title: h.title || h.name || String(h), confidence: h.confidence }));
                                        setRankedHypotheses(normalized);
                                        setChatHistory(prev => [...prev, { role: 'assistant', content: `Hypotheses updated (${normalized.length})` }]);
                                        return;
                                    }
                                    case 'approval_needed': {
                                        setApprovalContext({ command: maybe.command, reason: maybe.reason, risk: maybe.risk, impact: maybe.impact });
                                        setChatHistory(prev => [...prev, { role: 'assistant', content: `Approval needed: ${maybe.reason || 'See details'}` }]);
                                        return;
                                    }
                                    case 'coverage': {
                                        const missing = Array.isArray(maybe.missing) ? maybe.missing : [];
                                        setCoverageGaps(missing);
                                        setChatHistory(prev => [...prev, { role: 'assistant', content: `Coverage gaps: ${missing.join(', ') || 'none'}` }]);
                                        return;
                                    }
                                    case 'hint': {
                                        const text = maybe.message || maybe.hint;
                                        if (text) {
                                            setAgentHints(prev => [...prev, text]);
                                            setChatHistory(prev => [...prev, { role: 'assistant', content: `Hint: ${text}` }]);
                                        }
                                        return;
                                    }
                                    case 'verification': {
                                        const met = !!maybe.met;
                                        const reason = maybe.reason || '';
                                        setGoalVerification({ met, reason });
                                        setChatHistory(prev => [...prev, { role: 'assistant', content: `Goal status: ${met ? 'MET' : 'NOT MET'} ‚Äî ${reason}` }]);
                                        if (!met && autoExtendEnabled && !llmLoading) {
                                            setTimeout(() => {
                                                if (goalVerification && goalVerification.met) return;
                                                sendMessage('[EXTEND] Extend investigation automatically: collect missing signals, diversify commands, use MCP tools if available, and re-evaluate hypotheses.');
                                            }, 500);
                                        }
                                        return;
                                    }
                                    case 'plan_bias': {
                                        setExtendedMode({ preferred_checks: maybe.preferred_checks || [], prefer_mcp_tools: !!maybe.prefer_mcp_tools });
                                        setChatHistory(prev => [...prev, { role: 'assistant', content: `Extended mode: prioritizing ${Array.isArray(maybe.preferred_checks) ? maybe.preferred_checks.join(', ') : 'broader coverage'}${maybe.prefer_mcp_tools ? ' + MCP tools' : ''}` }]);
                                        return;
                                    }
                                    default: {
                                        // fall through to normal handling
                                    }
                                }
                            }
                        } catch { /* not JSON, continue */ }

                        // Parse Scout JSON for better display
                        if (step.role === 'SCOUT') {
                            try {
                                const json = JSON.parse(step.content);
                                command = json.command;
                                // For Python commands, we don't need to prepend the command as PythonCodeBlock handles it
                                if (command && command.startsWith('python:')) {
                                    content = json.output;
                                } else {
                                    // ToolMessage component handles command display in header/body.
                                    // Don't duplicate it in the content.
                                    content = json.output;
                                }

                                // Track command in streaming progress
                                const existingIdx = commandHistoryRef.current.findIndex(c => c.command === json.command && c.status === 'running');

                                if (existingIdx !== -1) {
                                    // Update existing running command
                                    if (json.output) {
                                        commandHistoryRef.current[existingIdx] = {
                                            ...commandHistoryRef.current[existingIdx],
                                            status: 'success',
                                            output: json.output,
                                            summary: generateCommandSummary(json.command, json.output)
                                        };
                                    }
                                } else {
                                    // Add new command
                                    // If output is empty, it's a 'command_selected' event -> running
                                    // If output is present, it's a 'command_output' event -> success (or we missed the start event)
                                    const isRunning = !json.output && step.content.includes('"output":""');

                                    // Check for exact duplicate (same command, same output, recently added) to prevent strict-mode double-renders
                                    const lastCmd = commandHistoryRef.current[commandHistoryRef.current.length - 1];
                                    const isDuplicate = lastCmd && lastCmd.command === json.command && lastCmd.output === json.output && (Date.now() - lastCmd.timestamp < 1000);

                                    if (!isDuplicate) {
                                        const cmdExecution: CommandExecution = {
                                            command: json.command,
                                            status: isRunning ? 'running' : 'success',
                                            output: json.output,
                                            summary: isRunning ? 'Executing...' : generateCommandSummary(json.command, json.output),
                                            timestamp: Date.now()
                                        };
                                        commandHistoryRef.current.push(cmdExecution);
                                    }
                                }

                                setStreamingPhase(prev => prev ? {
                                    ...prev,
                                    phase: 'executing',
                                    message: 'Running kubectl commands...',
                                    currentStep: json.command,
                                    commandHistory: [...commandHistoryRef.current]
                                } : null);
                            } catch (e) { /* keep raw content */ }
                        }

                        // Filter UI visibility based on user preference:
                        // 1. SUPERVISOR -> Show as "Thinking"
                        // 2. SCOUT -> Show as Tool (Terminal)
                        // 3. SPECIALIST -> Show as Tool (MCP)

                        const uiRole = step.role === 'SUPERVISOR' ? 'assistant' : 'tool';

                        let contentToShow = content;
                        if (step.role === 'SUPERVISOR') {
                            contentToShow = `üß† Thinking: ${step.content}`;
                        } else if (step.role === 'SPECIALIST') {
                            // Ensure SPECIALIST content (MCP Tools) is shown
                            // We can strip the "**Using Tool**:" prefix if we want cleaner UI, but it's fine for now
                            contentToShow = step.content;
                            toolName = 'External Tool';
                        }

                        // Add to UI immediately
                        setChatHistory(prev => {
                            const last = prev[prev.length - 1];

                            // 1. Consolidate consecutive "Thinking" messages (SUPERVISOR)
                            if (step.role === 'SUPERVISOR' && last && last.role === 'assistant' && (last.content.includes('üß† Thinking') || last.content.includes('üß† Supervisor'))) {
                                return [
                                    ...prev.slice(0, -1),
                                    { ...last, content: last.content + "\n\n" + step.content }
                                ];
                            }

                            // 2. Consolidate consecutive Command messages (SCOUT)
                            // If we just added a "Running" command, and now we get the "Output/Success" for the same command, update it.
                            if (step.role === 'SCOUT' && last && last.role === 'tool' && last.command === command) {
                                return [
                                    ...prev.slice(0, -1),
                                    {
                                        ...last,
                                        content: contentToShow, // Update content with output
                                        // command is same
                                        toolName // Update toolname if changed
                                    }
                                ];
                            }

                            return [...prev, {
                                role: uiRole,
                                content: contentToShow,
                                toolName,
                                command
                            }];
                        });
                    },
                    // Pass conversation context (User + Assistant only, exclude tools/activity)
                    contextHistory,
                    // Pass abort signal for cancellation
                    controller.signal,
                    // Pass current Kubernetes context
                    currentContext,
                    // Pass LLM config for Python agent
                    {
                        endpoint: llmConfig.base_url,
                        provider: llmConfig.provider,
                        model: llmConfig.model,
                        executor_model: llmConfig.executor_model || undefined
                    },
                    // Pass available MCP tools for the agent to use
                    listRegisteredMcpTools(),
                    // Callbacks for plan updates
                    undefined, // onPlanCreated (handled by onPlanUpdate)
                    (plan, currentStep, totalSteps) => {
                        // Plan Updated (Live State)
                        setCurrentPlan(plan);
                        setPlanTotalSteps(totalSteps);
                        setInvestigationPlan(prev => {
                            if (!prev) return null;
                            return { ...prev, steps: plan };
                        });

                        // Update streaming phase with progress
                        setStreamingPhase(prev => prev ? {
                            ...prev,
                            stepsCompleted: currentStep,
                            totalSteps: totalSteps,
                            commandHistory: commandHistoryRef.current
                        } : null);
                    },
                    undefined, // onStepCompleted
                    undefined, // onStepFailed
                    () => {
                        // Plan complete - clear after a delay
                        setTimeout(() => {
                            setCurrentPlan(null);
                            setPlanTotalSteps(0);
                        }, 3000);
                    },
                    { thread_id: threadId } // baseParams
                );

                // Post-process final response to format kubectl output
                let formattedResult = result;

                // Detect if response contains raw kubectl pod list output
                if (result.includes('NAMESPACE') && result.includes('READY') && result.includes('STATUS') && result.includes('RESTARTS')) {
                    const formatted = formatFailingPods(result);
                    formattedResult = formatted.markdown;
                }

                // Fallback if the agent returned an empty final response
                if (!formattedResult || !String(formattedResult).trim()) {
                    const stepsCount = Array.isArray(currentPlan) ? currentPlan.length : 0;
                    const toolsUsed = (chatHistory.filter(m => m.role === 'tool').length);
                    formattedResult = `Investigation completed, but no final answer was provided.\n\nSummary:\n- Steps executed: ${stepsCount > 0 ? stepsCount : 'n/a'}\n- Tools used: ${toolsUsed}\n\nIf you want me to continue, click Extend investigation or ask a specific follow-up (e.g., 'show warning events' or 'list failing pods').`;
                }

                // Set streaming phase to complete
                setStreamingPhase({
                    phase: 'complete',
                    message: 'Investigation complete',
                    commandHistory: commandHistoryRef.current
                });

                setChatHistory(prev => [...prev, { role: 'assistant', content: formattedResult }]);
                setLlmLoading(false);
            } catch (e: any) {
                // Handle cancellation gracefully
                if (e?.message === 'CANCELLED' || abortControllerRef.current?.signal.aborted) {
                    console.log("Agent loop cancelled by user");
                    setLlmLoading(false);
                    return;
                }
                console.error("Agent Loop Failed:", e);
                const errorMsg = String(e || '');

                // Set streaming phase to error
                setStreamingPhase({
                    phase: 'error',
                    message: errorMsg || 'An error occurred',
                    commandHistory: commandHistoryRef.current
                });

                // Provider-specific error messages
                if (llmConfig.provider === 'ollama' && (errorMsg.includes("not found") || errorMsg.includes("404"))) {
                    setChatHistory(prev => [...prev, { role: 'assistant', content: `‚ùå **Model Missing**: Model "${llmConfig.model}" is not installed. Run \`ollama pull ${llmConfig.model}\` or select an available model in Settings.` }]);
                } else if (errorMsg.includes("404")) {
                    setChatHistory(prev => [...prev, { role: 'assistant', content: `‚ùå **API Error (404)**: Endpoint not found. Check your base URL and model name in Settings. Current: ${llmConfig.base_url} / ${llmConfig.model}` }]);
                } else if (errorMsg.includes("401") || errorMsg.includes("403") || errorMsg.includes("Unauthorized")) {
                    setChatHistory(prev => [...prev, { role: 'assistant', content: `‚ùå **Authentication Failed**: Check your API key in Settings.` }]);
                } else if (errorMsg.includes("connection") || errorMsg.includes("ECONNREFUSED") || errorMsg.includes("timeout")) {
                    setChatHistory(prev => [...prev, { role: 'assistant', content: `‚ùå **Connection Failed**: Cannot reach ${llmConfig.base_url}. Is the server running?` }]);
                } else {
                    setChatHistory(prev => [...prev, { role: 'assistant', content: `‚ùå Agent error: ${e}` }]);
                }
                setLlmLoading(false);
            }
        } catch (err: any) {
            setChatHistory(prev => [...prev, { role: 'assistant', content: `‚ùå Error: ${err}. Check your AI settings or provider connection.` }]);
            setStreamingPhase({
                phase: 'error',
                message: String(err) || 'An error occurred',
                commandHistory: commandHistoryRef.current
            });
        } finally {
            setLlmLoading(false);
            setInvestigationProgress(null);
            // Clear streaming phase after a delay to allow user to see final state
            setTimeout(() => setStreamingPhase(null), 3000);
        }
    };

    // Handle User Approval/Denial
    const handleApproval = async (approved: boolean) => {
        if (!approvalContext) return;

        // 1. Update UI state immediately
        const prevContext = approvalContext;
        setApprovalContext(null);

        setChatHistory(prev => [...prev, {
            role: 'assistant',
            content: approved
                ? `‚úÖ **Approved**: Executing \`${prevContext.command || 'action'}\`...`
                : `‚ùå **Denied**: Cancelled \`${prevContext.command || 'action'}\`.`
        }]);

        // If denied, we define the behavior (usually just stop, or verify.py handles denied state if we proceed)
        // With backend-only agent, we MUST call back with approved=False if we want the graph to know.

        setLlmLoading(true);
        setCurrentActivity(approved ? "üöÄ Executing approved action..." : "üõë Processing denial...");

        try {
            // Re-enter the agent loop with the approved flag
            // We reuse the existing executors logic from sendMessage
            await runAgentLoop(
                approved ? "User approved execution." : "User declined execution.",
                // LLM Executor
                {
                    callLLM: async (prompt: string, systemPrompt: string, options: any) => {
                        return await invoke('call_llm', {
                            model: options?.model || 'opspilot-brain',
                            prompt,
                            systemPrompt,
                            temperature: options?.temperature || 0.7,
                            thread_id: threadId,
                        });
                    },
                    callLLMStream: async () => { }
                },
                // Fast Executor
                async (prompt: string, systemPrompt: string, options: any) => {
                    // Fallback to brain model logic if no executor
                    const config = llmConfig.executor_model ? { ...llmConfig, model: llmConfig.executor_model } : llmConfig;
                    return await invoke<string>("call_llm", {
                        config,
                        prompt,
                        systemPrompt,
                        conversationHistory: [],
                        thread_id: threadId,
                    });
                },
                // Progress
                (msg) => setCurrentActivity(msg),
                // Step
                (step) => {
                    // Reuse step handling logic partially? 
                    // To avoid code duplication we should extract this, but for now we simplify:
                    // We only care about displaying main output or new approvals
                    setChatHistory(prev => {
                        // ... simplistic append ...
                        return [...prev, {
                            role: step.role === 'SUPERVISOR' ? 'assistant' : 'tool',
                            content: step.role === 'SUPERVISOR' ? `üß† ${step.content}` : step.content
                        }];
                    });

                    // IMPORTANT: We need to parse backend events too (like done, or another approval)
                    // The runAgentLoop calls this callback with structured events too?
                    // Actually runAgentLoop in agentOrchestrator handles the parsing and calls onStep with simplified content.
                    // BUT it calls onApprovalRequired separately if we pass it!
                },
                [], // context history (not critical for resume)
                abortControllerRef.current?.signal,
                currentContext,
                { endpoint: llmConfig.base_url, provider: llmConfig.provider, model: llmConfig.model },
                listRegisteredMcpTools(),
                undefined,
                (plan, currentStep, totalSteps) => {
                    setCurrentPlan(plan);
                    setPlanTotalSteps(totalSteps);
                },
                undefined,
                undefined,
                () => {
                    setTimeout(() => setCurrentPlan(null), 3000);
                },
                {
                    thread_id: threadId,
                    approved: approved,
                    onApprovalRequired: (context) => {
                        setApprovalContext(context);
                        setChatHistory(prev => [...prev, { role: 'assistant', content: `üö® **Approval Needed**: ${context.reason}` }]);
                    }
                }
            );
        } catch (e: any) {
            setChatHistory(prev => [...prev, { role: 'assistant', content: `‚ùå Error during execution: ${e.message}` }]);
        } finally {
            setLlmLoading(false);
            setCurrentActivity("");
        }
    };

    // If minimized, show just a small pill (only if not embedded)
    if (isMinimized && !embedded) {
        return createPortal(
            <div
                onClick={onToggleMinimize}
                className="fixed bottom-4 right-4 z-50 flex items-center gap-2.5 px-5 py-2.5 bg-gradient-to-r from-violet-600 via-purple-600 to-fuchsia-600 hover:from-violet-500 hover:via-purple-500 hover:to-fuchsia-500 rounded-2xl shadow-xl shadow-purple-500/25 cursor-pointer transition-all duration-300 group hover:scale-105 hover:shadow-purple-500/40"
            >
                <div className="relative">
                    <Sparkles size={18} className="text-white" />
                    <div className="absolute -top-0.5 -right-0.5 w-2 h-2 bg-green-400 rounded-full animate-pulse" />
                </div>
                <span className="text-white font-semibold text-sm tracking-tight">AI Assistant</span>
                {chatHistory.length > 0 && (
                    <span className="text-xs px-2 py-0.5 rounded-full bg-white/20 text-white font-medium backdrop-blur-sm">{chatHistory.filter(m => m.role === 'assistant').length}</span>
                )}
                <button
                    onClick={(e) => { e.stopPropagation(); onClose?.(); }}
                    className="ml-1 p-1 rounded-full hover:bg-white/20 text-white/70 hover:text-white transition-all opacity-70 hover:opacity-100"
                >
                    <X size={14} />
                </button>
            </div>,
            document.body
        );
    }

    const panelContent = (
        <div className={embedded
            ? "flex flex-col h-full w-full bg-[#111113] border-l border-white/5 relative"
            : `fixed ${isExpanded ? 'inset-4' : 'bottom-4 right-4 w-[480px] h-[640px]'} z-50 flex flex-col bg-gradient-to-b from-[#1a1a2e] to-[#16161a] border border-white/10 rounded-2xl shadow-2xl shadow-black/50 transition-all duration-300 overflow-hidden`
        }>
            {/* Decorative background effects */}
            <div className="absolute top-0 left-0 right-0 h-32 bg-gradient-to-b from-purple-500/10 via-fuchsia-500/5 to-transparent pointer-events-none" />
            <div className="absolute -top-24 -right-24 w-48 h-48 bg-purple-500/20 rounded-full blur-3xl pointer-events-none" />
            <div className="absolute -bottom-24 -left-24 w-48 h-48 bg-cyan-500/10 rounded-full blur-3xl pointer-events-none" />

            {/* Header */}
            <div className="relative z-50 flex items-center justify-between px-4 py-3.5 border-b border-white/10 bg-[#16161a] shrink-0 shadow-md">
                <div className="flex items-center gap-3 min-w-0 flex-1">
                    <div className="relative shrink-0">
                        <div className="absolute inset-0 bg-gradient-to-br from-violet-500 to-fuchsia-500 rounded-xl blur-sm opacity-60" />
                        <div className="relative p-2 rounded-xl bg-gradient-to-br from-violet-500 to-fuchsia-500">
                            <Sparkles size={16} className="text-white" />
                        </div>
                    </div>
                    <div className="min-w-0">
                        <h3 className="font-semibold text-white text-sm tracking-tight truncate">AI Assistant</h3>
                        <div className="flex items-center gap-2 flex-wrap">
                            <button
                                onClick={() => setShowSettings(true)}
                                className="text-[10px] text-zinc-400 hover:text-zinc-300 flex items-center gap-1.5 transition-colors group"
                            >
                                <div className={`w-1.5 h-1.5 rounded-full ${llmStatus?.connected ? 'bg-emerald-400 shadow-sm shadow-emerald-400/50' : 'bg-red-400 shadow-sm shadow-red-400/50'}`} />
                                <span className="truncate">{llmConfig.provider === 'ollama' ? 'Ollama' : llmConfig.provider === 'openai' ? 'OpenAI' : llmConfig.provider === 'anthropic' ? 'Anthropic' : 'Custom'}</span>
                                <span className="text-zinc-500">‚Ä¢</span>
                                <span className="text-zinc-500 group-hover:text-zinc-400 truncate">{llmConfig.model.split(':')[0]}</span>
                                <ChevronDown size={10} className="text-zinc-500 shrink-0" />
                            </button>
                            {extendedMode && (
                                <span
                                    className="text-[10px] px-2 py-0.5 rounded-full bg-violet-500/15 border border-violet-500/30 text-violet-300"
                                    title={`Extended mode ‚Ä¢ Checks: ${extendedMode.preferred_checks?.join(', ') || 'broader coverage'}${extendedMode.prefer_mcp_tools ? ' ‚Ä¢ Prefers MCP tools' : ''}`}
                                >
                                    Extended
                                </span>
                            )}
                            {currentContext && (
                                <span className="text-[10px] text-cyan-400/80 flex items-center gap-1 truncate max-w-[150px]" title={`Kubernetes Context: ${currentContext}`}>
                                    <span className="text-zinc-500">‚Üí</span>
                                    <span className="truncate">{currentContext}</span>
                                </span>
                            )}
                        </div>
                    </div>
                </div>

                {/* Header Actions */}
                <div className="flex items-center gap-1.5 bg-[#27272a] rounded-lg p-1 border border-white/20 shadow-md shrink-0 ml-2">
                    <button
                        onClick={() => {
                            setChatHistory([]);
                            localStorage.removeItem('ops-pilot-chat-history');
                            setCurrentPlan(null);
                            setPlanTotalSteps(0);
                            setInvestigationProgress(null);
                            setPhaseTimeline([]);
                            setRankedHypotheses([]);
                            setCoverageGaps([]);
                            setAgentHints([]);
                            setGoalVerification(null);
                            setApprovalContext(null);
                            setExtendedMode(null);
                            // Rotate thread_id to start fresh session
                            const newThreadId = crypto.randomUUID();
                            setThreadId(newThreadId);
                            localStorage.setItem('agent_thread_id', newThreadId);
                        }}
                        className="p-1.5 text-zinc-400 hover:text-rose-400 hover:bg-rose-500/10 rounded-md transition-all"
                        title="Clear Chat History"
                    >
                        <Trash2 size={14} />
                    </button>
                    {llmLoading && (
                        <>
                            <div className="w-px h-3 bg-white/10 mx-0.5" />
                            <button
                                onClick={cancelAnalysis}
                                disabled={isCancelling}
                                className="p-1.5 text-red-400 hover:text-red-300 hover:bg-red-500/10 rounded-md transition-all disabled:opacity-50"
                                title={isCancelling ? "Stopping..." : "Stop Generation"}
                            >
                                <StopCircle size={14} className={isCancelling ? "animate-spin" : ""} />
                            </button>
                        </>
                    )}
                    <div className="w-px h-3 bg-white/10 mx-0.5" />
                    <button
                        onClick={() => setShowSettings(true)}
                        className="p-1.5 rounded-md hover:bg-white/10 text-zinc-300 hover:text-white transition-all"
                        title="Settings"
                    >
                        <Settings size={14} />
                    </button>
                    <div className="w-px h-3 bg-white/10 mx-0.5" />
                    <button
                        onClick={onToggleMinimize}
                        className="p-1.5 rounded-md hover:bg-white/10 text-zinc-300 hover:text-white transition-all"
                        title="Minimize"
                    >
                        <Minus size={14} />
                    </button>
                    <button
                        onClick={() => setIsExpanded(!isExpanded)}
                        className="p-1.5 rounded-md hover:bg-white/10 text-zinc-300 hover:text-white transition-all"
                        title={isExpanded ? "Restore" : "Expand"}
                    >
                        {isExpanded ? <Minimize2 size={14} /> : <Maximize2 size={14} />}
                    </button>
                    <button
                        onClick={onClose}
                        className="p-1.5 rounded-md hover:bg-red-500/20 text-zinc-300 hover:text-red-400 transition-all"
                        title="Close"
                    >
                        <X size={16} />
                    </button>
                </div>
            </div>

            {/* Settings Panel Modal */}
            {showSettings && createPortal(
                <>
                    {/* Backdrop */}
                    <div
                        className="fixed inset-0 bg-black/70 backdrop-blur-md z-[59] flex items-center justify-center p-4 animate-in fade-in duration-200"
                        onClick={() => setShowSettings(false)}
                    >
                        {/* Modal Container */}
                        <div
                            className="relative w-full max-w-2xl max-h-[90vh] bg-gradient-to-br from-[#1a1a2e] via-[#16161a] to-[#1a1a2e] rounded-3xl shadow-2xl border border-white/10 overflow-hidden animate-in zoom-in-95 duration-300"
                            onClick={(e) => e.stopPropagation()}
                        >
                            {/* Decorative gradient orbs */}
                            <div className="absolute -top-24 -right-24 w-48 h-48 bg-violet-500/30 rounded-full blur-3xl pointer-events-none" />
                            <div className="absolute -bottom-24 -left-24 w-48 h-48 bg-cyan-500/20 rounded-full blur-3xl pointer-events-none" />

                            {/* Content */}
                            <div className="relative z-10 overflow-y-auto max-h-[90vh]">
                                <LLMSettingsPanel
                                    config={llmConfig}
                                    onConfigChange={(newConfig) => {
                                        setLlmConfig(newConfig);
                                        setShowSettings(false);
                                    }}
                                    onClose={() => setShowSettings(false)}
                                    systemSpecs={systemSpecs}
                                    kbProgress={kbProgress}
                                />
                            </div>
                        </div>
                    </div>
                </>,
                document.body
            )}

            {/* Messages */}
            <div
                ref={messagesContainerRef}
                className={`relative flex-1 min-h-0 scroll-smooth ${llmConfig.provider === 'claude-code'
                    ? 'overflow-hidden p-0'
                    : 'overflow-y-auto p-4 space-y-4'
                    }`}
            >
                {/* Loading state while checking LLM - not for claude-code mode */}
                {llmConfig.provider !== 'claude-code' && checkingLLM && chatHistory.length === 0 && (
                    <div className="flex flex-col items-center justify-center py-24 px-6">
                        <div className="relative mb-8">
                            <div className="absolute inset-0 bg-violet-500/30 blur-xl rounded-full animate-pulse" />
                            <div className="relative w-16 h-16 border-4 border-violet-500/30 border-t-violet-400 rounded-full animate-spin" />
                            <div className="absolute inset-0 flex items-center justify-center">
                                <Sparkles size={20} className="text-violet-200 animate-pulse" />
                            </div>
                        </div>
                        <h3 className="text-lg font-semibold text-white mb-2 animate-pulse">Initializing AI...</h3>
                        <p className="text-sm text-zinc-400 text-center max-w-xs">
                            Checking connection and model status. <br />
                            <span className="text-xs text-zinc-500 mt-2 block opacity-80">(This may take a moment if downloading)</span>
                        </p>
                    </div>
                )}


                {/* Show setup prompt if LLM not connected OR if there is an error (like model missing) - not for claude-code */}
                {
                    llmConfig.provider !== 'claude-code' && !checkingLLM && (!llmStatus?.connected || !!llmStatus?.error) && chatHistory.length === 0 && (
                        <div className="flex flex-col items-center justify-center py-12 px-6 max-w-lg mx-auto w-full">
                            {llmConfig.provider === 'ollama' ? (
                                <div className="w-full bg-zinc-900/50 rounded-2xl border border-white/10 overflow-hidden shadow-2xl">
                                    <OllamaSetupInstructions
                                        status={llmStatus ? {
                                            ollama_running: llmStatus.connected,
                                            model_available: !llmStatus.error?.includes('not found') && !llmStatus.error?.includes('missing'),
                                            available_models: llmStatus.available_models || [],
                                            model_name: llmConfig.model,
                                            error: llmStatus.error
                                        } : null}
                                        onRetry={checkLLMStatus}
                                    />
                                </div>
                            ) : (
                                <>
                                    <div className="relative mb-6">
                                        <div className="absolute inset-0 bg-gradient-to-br from-orange-500 to-red-500 rounded-2xl blur-xl opacity-20" />
                                        <div className="relative w-20 h-20 rounded-2xl bg-gradient-to-br from-orange-500/20 to-red-500/20 flex items-center justify-center border border-orange-500/20 backdrop-blur-sm">
                                            <AlertCircle size={36} className="text-orange-400" />
                                        </div>
                                    </div>
                                    <h3 className="text-xl font-bold text-white mb-2 tracking-tight">Setup Required</h3>
                                    <p className="text-sm text-zinc-400 text-center mb-1 max-w-[280px]">{llmStatus?.error || 'Configure your AI provider to start chatting.'}</p>
                                    <p className="text-xs text-zinc-500 mb-6 font-mono">{llmConfig.provider} ‚Ä¢ {llmConfig.model}</p>
                                    <button
                                        onClick={() => setShowSettings(true)}
                                        className="group px-5 py-2.5 rounded-xl bg-gradient-to-r from-violet-600 to-fuchsia-600 hover:from-violet-500 hover:to-fuchsia-500 text-white font-semibold text-sm transition-all duration-300 flex items-center gap-2 shadow-lg shadow-purple-500/25 hover:shadow-purple-500/40 hover:scale-105"
                                    >
                                        <Settings size={16} className="group-hover:rotate-90 transition-transform duration-300" />
                                        Configure AI
                                    </button>
                                </>
                            )}
                        </div>
                    )
                }

                {/* Normal chat welcome screen - only show when LLM is ready AND NO ERROR - not for claude-code */}
                {
                    llmConfig.provider !== 'claude-code' && !checkingLLM && llmStatus?.connected && !llmStatus?.error && chatHistory.length === 0 && (
                        <div className="flex flex-col items-center justify-center py-10 px-6">
                            <div className="relative mb-6">
                                <div className="absolute inset-0 bg-gradient-to-br from-violet-500 to-cyan-500 rounded-2xl blur-xl opacity-20 animate-pulse" />
                                <div className="relative w-20 h-20 rounded-2xl bg-gradient-to-br from-violet-500/20 to-cyan-500/20 flex items-center justify-center border border-violet-500/20 backdrop-blur-sm">
                                    <Sparkles size={36} className="text-violet-400" />
                                </div>
                            </div>
                            <h3 className="text-xl font-bold text-white mb-2 tracking-tight">Hey there! üëã</h3>
                            {loadingWelcomeJoke ? (
                                <p className="text-sm text-zinc-400 text-center mb-1 max-w-[320px] italic animate-pulse">
                                    Thinking of something funny...
                                </p>
                            ) : welcomeJoke ? (
                                <div className="flex items-center gap-2 mb-1">
                                    <p className="text-sm text-zinc-300 text-center max-w-[320px] italic">
                                        {welcomeJoke}
                                    </p>
                                    <button
                                        onClick={fetchNewWelcomeJoke}
                                        className="p-1.5 text-zinc-500 hover:text-violet-400 hover:bg-violet-500/10 rounded-lg transition-all"
                                        title="Get another joke"
                                    >
                                        <RefreshCw size={14} />
                                    </button>
                                </div>
                            ) : (
                                <p className="text-sm text-zinc-400 text-center mb-1 max-w-[300px]">
                                    Ask me anything about your cluster's health, resources, or issues.
                                </p>
                            )}
                            <p className="text-xs text-zinc-500 text-center mt-2 max-w-[300px]">What can I help you debug today?</p>
                            <div className="flex flex-col items-center gap-1 mb-6">
                                <p className="text-xs text-zinc-500 flex items-center gap-1.5">
                                    <span className="w-1.5 h-1.5 rounded-full bg-emerald-400 shadow-sm shadow-emerald-400/50" />
                                    {llmStatus.provider} ‚Ä¢ {llmConfig.model.split(':')[0]}
                                </p>
                                {/* Embedding model status indicator */}
                                {embeddingStatus && (
                                    <p className={`text - [10px] flex items - center gap - 1.5 ${embeddingStatus === 'loading' ? 'text-amber-400' :
                                        embeddingStatus === 'ready' ? 'text-zinc-500' :
                                            'text-red-400'
                                        } `}>
                                        {embeddingStatus === 'loading' && (
                                            <>
                                                <Loader2 size={10} className="animate-spin" />
                                                {embeddingMessage || 'Loading knowledge base...'}
                                            </>
                                        )}
                                        {embeddingStatus === 'ready' && (
                                            <>
                                                <span className="w-1.5 h-1.5 rounded-full bg-cyan-400/50" />
                                                Knowledge base ready
                                            </>
                                        )}
                                        {embeddingStatus === 'error' && (
                                            <>
                                                <AlertCircle size={10} />
                                                KB unavailable
                                            </>
                                        )}
                                    </p>
                                )}
                            </div>
                            <div className="flex flex-wrap gap-2 justify-center max-w-[360px]">
                                {[
                                    { icon: 'üîç', text: 'Find cluster issues' },
                                    { icon: 'üöÄ', text: 'Auto-Diagnose Cluster' },
                                    { icon: 'üîÑ', text: 'Crashlooping pods' },
                                    { icon: 'üìä', text: 'Health overview' }
                                ].map(q => (
                                    <button
                                        key={q.text}
                                        onClick={() => sendMessage(q.text === 'Auto-Diagnose Cluster' ? 'Perform an autonomous deep dive on the cluster health. Use the Autonomous Playbook.' : q.text)}
                                        className="px-3.5 py-2 text-xs bg-white/5 hover:bg-white/10 text-zinc-300 hover:text-white rounded-xl transition-all border border-white/5 hover:border-white/10 flex items-center gap-2"
                                    >
                                        <span>{q.icon}</span>
                                        {q.text}
                                    </button>
                                ))}
                            </div>
                        </div>


                    )}

                {/* Plan Progress UI - Show when plan is active (not for claude-code) */}
                {llmConfig.provider !== 'claude-code' && currentPlan && currentPlan.length > 0 && (
                    <PlanProgressUI
                        plan={currentPlan}
                        totalSteps={planTotalSteps}
                        className="mb-4"
                    />
                )}

                {/* Claude Code Mode - Integrated Claude Code Panel */}
                {llmConfig.provider === 'claude-code' && (
                    <ClaudeCodePanel
                        currentContext={currentContext}
                        embedded={true}
                        className="h-full w-full"
                    />
                )}

                {/* Standard Chat UI for non-Claude-Code providers */}
                {llmConfig.provider !== 'claude-code' && (
                    /* Standard Chat History View */
                    groupedHistory.map((group, i) => {
                        if (group.type === 'raw') {
                            // Fallback for raw messages (likely system or orphaned)
                            return (
                                <div key={i} className="pl-6 pb-2">
                                    <ThinkingMessage content={group.msg.content} isLatest={false} />
                                </div>
                            );
                        }
                        if (group.type === 'system_steps') {
                            const isActive = i === groupedHistory.length - 1 && !group.answer;
                            return (
                                <div key={i}>
                                    {isActive && streamingPhase ? (
                                        <div className="pl-6 pb-4">
                                            <StreamingProgressCard phase={streamingPhase} />
                                        </div>
                                    ) : (
                                        <InvestigationTimeline
                                            steps={group.steps}
                                            isActive={false}
                                        />
                                    )}
                                </div>
                            )
                        }

                        // Interaction Group
                        const isLastGroup = i === groupedHistory.length - 1;
                        const isInvestigating = isLastGroup && !group.answer;

                        return (
                            <div key={i} className="animate-in fade-in slide-in-from-bottom-2 duration-300">
                                {/* User Message */}
                                {group.user && (
                                    <div className="relative pl-6 pb-4">
                                        <div className="absolute left-0 top-1 w-3 h-3 rounded-full bg-violet-500 ring-4 ring-violet-500/20" />
                                        <div className="absolute left-[5px] top-4 bottom-0 w-0.5 bg-gradient-to-b from-violet-500/50 to-transparent" />
                                        <div className="ml-2">
                                            <div className="flex items-center gap-2 mb-1">
                                                <span className="text-[10px] font-medium text-violet-400 uppercase tracking-wider">Task</span>
                                            </div>
                                            <div className="bg-gradient-to-br from-violet-600/20 to-fuchsia-600/20 rounded-lg px-3 py-2 border border-violet-500/30">
                                                <p className="text-sm text-white">{group.user.content}</p>
                                            </div>
                                        </div>
                                    </div>
                                )}

                                {/* Timeline */}
                                {isInvestigating && streamingPhase ? (
                                    <div className="pl-6 pb-4">
                                        <StreamingProgressCard phase={streamingPhase} />
                                    </div>
                                ) : group.steps && group.steps.length > 0 ? (
                                    <InvestigationTimeline
                                        steps={group.steps}
                                        isActive={false}
                                    />
                                ) : null}

                                {/* Final Answer */}
                                {group.answer && (
                                    <div className="relative pl-6 pb-4">
                                        <div className="absolute left-0 top-1 w-3 h-3 rounded-full bg-emerald-500 ring-4 ring-emerald-500/20" />
                                        <div className="ml-2">
                                            <div className="flex items-center gap-2 mb-2">
                                                <span className="text-[10px] font-medium text-emerald-400 uppercase tracking-wider">Answer</span>
                                                <Sparkles size={10} className="text-emerald-400" />
                                            </div>
                                            <div className="bg-[#0d1117] rounded-lg border border-[#21262d] overflow-hidden">
                                                <div className="px-4 py-3 prose prose-invert prose-sm max-w-none">
                                                    <ReactMarkdown
                                                        remarkPlugins={[remarkGfm]}
                                                        components={{
                                                            p: ({ children }) => <p className="text-[13px] text-zinc-300 my-1.5 leading-relaxed">{children}</p>,
                                                            strong: ({ children }) => <strong className="text-white font-semibold">{children}</strong>,
                                                            em: ({ children }) => <em className="text-zinc-400 not-italic">{children}</em>,
                                                            code: ({ children }) => <code className="text-[11px] bg-black/40 px-1.5 py-0.5 rounded text-cyan-300 font-mono">{children}</code>,
                                                            pre: ({ children }) => <pre className="text-[11px] bg-black/40 p-2.5 rounded-lg overflow-x-auto my-2 font-mono">{children}</pre>,
                                                            ul: ({ children }) => <ul className="text-[13px] list-none ml-0 my-1.5 space-y-1">{children}</ul>,
                                                            ol: ({ children }) => <ol className="text-[13px] list-decimal ml-4 my-1.5 space-y-1">{children}</ol>,
                                                            li: ({ children }) => <li className="text-zinc-300 before:content-['‚Üí'] before:text-emerald-500 before:mr-2 before:font-bold">{children}</li>,
                                                            h1: ({ children }) => <h1 className="text-sm font-bold text-white mt-4 mb-2 flex items-center gap-2 border-b border-zinc-700 pb-2">{children}</h1>,
                                                            h2: ({ children }) => <h2 className="text-sm font-bold text-emerald-300 mt-4 mb-2 flex items-center gap-2"><span className="w-1.5 h-1.5 rounded-full bg-emerald-400" />{children}</h2>,
                                                            h3: ({ children }) => <h3 className="text-sm font-semibold text-cyan-300 mt-3 mb-1.5">{children}</h3>,
                                                            blockquote: ({ children }) => <blockquote className="border-l-2 border-amber-500 pl-3 my-2 text-amber-200/80 italic">{children}</blockquote>,
                                                        }}
                                                    >
                                                        {fixMarkdownHeaders(group.answer.content)}
                                                    </ReactMarkdown>
                                                    {group.answer.isStreaming && group.answer.content && (
                                                        <span className="inline-block w-1.5 h-4 bg-emerald-400 animate-pulse ml-0.5" />
                                                    )}
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                )}
                            </div>
                        );
                    })
                )}

                {/* Loading State with Cancel Button */}
                {
                    llmLoading && (
                        <div className="relative pl-6 pb-3 animate-in fade-in slide-in-from-bottom-2 duration-300">
                            {/* Timeline dot - pulsing */}
                            <div className="absolute left-0 top-1 w-3 h-3 rounded-full bg-violet-500 ring-4 ring-violet-500/20 animate-pulse" />
                            <div className="absolute left-[5px] top-4 bottom-0 w-0.5 bg-gradient-to-b from-violet-500/50 to-transparent" />

                            <div className="ml-2">
                                <div className="flex items-center gap-2">
                                    <span className="text-[10px] font-medium text-violet-400 uppercase tracking-wider">Processing</span>
                                    <div className="flex gap-1">
                                        <div className="w-1.5 h-1.5 rounded-full bg-violet-400 animate-bounce" style={{ animationDelay: '0ms' }} />
                                        <div className="w-1.5 h-1.5 rounded-full bg-violet-400 animate-bounce" style={{ animationDelay: '150ms' }} />
                                        <div className="w-1.5 h-1.5 rounded-full bg-violet-400 animate-bounce" style={{ animationDelay: '300ms' }} />
                                    </div>
                                    {/* Cancel button */}
                                    <button
                                        onClick={cancelAnalysis}
                                        disabled={isCancelling}
                                        className="ml-auto px-3 py-1.5 text-[10px] font-bold text-red-400 hover:text-red-300 bg-zinc-900 border border-red-500/40 hover:border-red-500 hover:bg-red-500/10 rounded-md shadow-sm transition-all flex items-center gap-2 disabled:opacity-50 uppercase tracking-wider"
                                        title="Stop analysis"
                                    >
                                        <StopCircle size={14} className={isCancelling ? "animate-spin" : ""} />
                                        {isCancelling ? 'STOPPING...' : 'STOP GENERATING'}
                                    </button>
                                </div>
                                {!streamingPhase && <p className="text-sm text-zinc-300 mt-2 font-medium">{currentActivity}</p>}

                                {/* Investigation Chain of Thought Panel */}
                                {investigationProgress && (
                                    <div className="mt-3 p-3 bg-zinc-800/50 rounded-lg border border-zinc-700/50">
                                        {/* Progress Bar */}
                                        <div className="flex items-center gap-2 mb-2">
                                            <div className="flex-1 h-1.5 bg-zinc-700 rounded-full overflow-hidden">
                                                <div
                                                    className={`h - full transition - all duration - 300 ${investigationProgress.confidence.level === 'HIGH' ? 'bg-green-500' :
                                                        investigationProgress.confidence.level === 'MEDIUM' ? 'bg-yellow-500' : 'bg-red-500'
                                                        } `}
                                                    style={{ width: `${investigationProgress.confidence.score}% ` }}
                                                />
                                            </div>
                                            <span className={`text - [10px] font - mono font - bold ${investigationProgress.confidence.level === 'HIGH' ? 'text-green-400' :
                                                investigationProgress.confidence.level === 'MEDIUM' ? 'text-yellow-400' : 'text-red-400'
                                                } `}>
                                                {investigationProgress.confidence.level} ({investigationProgress.confidence.score}%)
                                            </span>
                                        </div>

                                        {/* Stats Row */}
                                        <div className="flex items-center gap-4 text-[10px] text-zinc-400 mb-2">
                                            <span>Step {investigationProgress.iteration}/{investigationProgress.maxIterations}</span>
                                            <span>Phase: {investigationProgress.phase}</span>
                                            <span>Evidence: {investigationProgress.usefulEvidence}</span>
                                        </div>

                                        {/* Hypotheses */}
                                        {investigationProgress.hypotheses.length > 0 && (
                                            <div className="space-y-1">
                                                <div className="text-[10px] font-medium text-zinc-300">Hypotheses:</div>
                                                {investigationProgress.hypotheses.slice(0, 3).map(h => (
                                                    <div key={h.id} className="flex items-center gap-2 text-[10px]">
                                                        <span className={`w - 2 h - 2 rounded - full ${h.status === 'confirmed' ? 'bg-green-500' :
                                                            h.status === 'refuted' ? 'bg-red-500' :
                                                                'bg-yellow-500 animate-pulse'
                                                            } `} />
                                                        <span className={`font - mono ${h.status === 'confirmed' ? 'text-green-400' :
                                                            h.status === 'refuted' ? 'text-red-400 line-through' :
                                                                'text-zinc-300'
                                                            } `}>
                                                            {h.id}: {h.description.slice(0, 50)}{h.description.length > 50 ? '...' : ''}
                                                        </span>
                                                    </div>
                                                ))}
                                            </div>
                                        )}
                                    </div>
                                )}
                            </div>
                        </div>
                    )}

                <div ref={chatEndRef} />
            </div>

            {/* Side insights panel for phases/hypotheses/coverage/approval/hints */}
            {(phaseTimeline.length > 0 || rankedHypotheses.length > 0 || coverageGaps.length > 0 || approvalContext || agentHints.length > 0 || extendedMode) && (
                <div className="px-4 pb-3 bg-[#16161a] border-t border-white/5">
                    <div className="grid grid-cols-1 md:grid-cols-2 gap-3">
                        {extendedMode && (
                            <div className="rounded-lg p-3 border bg-violet-500/10 border-violet-500/30">
                                <div className="text-[10px] font-medium text-zinc-300 mb-1">Mode</div>
                                <div className="text-[11px] text-violet-300">Extended Investigation</div>
                                {(extendedMode.preferred_checks && extendedMode.preferred_checks.length > 0) && (
                                    <div className="text-[11px] text-zinc-300 mt-1">Checks: {extendedMode.preferred_checks.join(', ')}</div>
                                )}
                                {extendedMode.prefer_mcp_tools && (
                                    <div className="text-[11px] text-zinc-300 mt-1">Prefers MCP Tools</div>
                                )}
                            </div>
                        )}
                        {goalVerification && (
                            <div className={`rounded-lg p-3 border ${goalVerification.met ? 'bg-emerald-500/10 border-emerald-500/30' : 'bg-rose-500/10 border-rose-500/30'}`}>
                                <div className="text-[10px] font-medium text-zinc-300 mb-1">Goal</div>
                                <div className={`text-[11px] ${goalVerification.met ? 'text-emerald-300' : 'text-rose-300'}`}>
                                    {goalVerification.met ? 'MET' : 'NOT MET'}
                                </div>
                                {goalVerification.reason && (
                                    <div className="text-[11px] text-zinc-300 mt-1">{goalVerification.reason}</div>
                                )}
                                <div className="mt-2 flex items-center gap-2">
                                    {!goalVerification.met && (
                                        <button
                                            onClick={() => sendMessage('[EXTEND] Please extend investigation: collect missing signals (nodes/pods/events/resource-usage), try MCP tools if available, broaden command diversity, and re-evaluate hypotheses.')}
                                            className="px-3 py-1.5 text-[11px] rounded-md bg-violet-600/20 border border-violet-500/40 hover:bg-violet-600/30 text-violet-200 transition-all"
                                        >
                                            Extend investigation
                                        </button>
                                    )}
                                    <label className="text-[10px] text-zinc-400 flex items-center gap-1">
                                        <input type="checkbox" checked={autoExtendEnabled} onChange={(e) => setAutoExtendEnabled(e.target.checked)} />
                                        Auto-extend if NOT MET
                                    </label>
                                </div>
                            </div>
                        )}
                        {phaseTimeline.length > 0 && (
                            <div className="bg-[#0d1117] rounded-lg border border-[#21262d] p-3">
                                <div className="text-[10px] font-medium text-zinc-300 mb-2">Phases</div>
                                <div className="flex flex-wrap gap-1">
                                    {phaseTimeline.map((p, idx) => (
                                        <span key={idx} className="px-2 py-1 text-[10px] rounded-full bg-violet-500/10 border border-violet-500/30 text-violet-300">{p.name}</span>
                                    ))}
                                </div>
                            </div>
                        )}
                        {rankedHypotheses.length > 0 && (
                            <div className="bg-[#0d1117] rounded-lg border border-[#21262d] p-3">
                                <div className="text-[10px] font-medium text-zinc-300 mb-2">Hypotheses</div>
                                <ul className="space-y-1">
                                    {rankedHypotheses.map((h, i) => (
                                        <li key={i} className="text-[11px] text-zinc-300">{h.title}{typeof h.confidence === 'number' ? ` (${Math.round(h.confidence * 100)}%)` : ''}</li>
                                    ))}
                                </ul>
                            </div>
                        )}
                        {coverageGaps.length > 0 && (
                            <div className="bg-[#0d1117] rounded-lg border border-[#21262d] p-3">
                                <div className="text-[10px] font-medium text-zinc-300 mb-2">Coverage Gaps</div>
                                <ul className="space-y-1">
                                    {coverageGaps.map((c, i) => (<li key={i} className="text-[11px] text-amber-300">{c}</li>))}
                                </ul>
                            </div>
                        )}
                        {approvalContext && (
                            <div className="bg-[#0d1117] rounded-lg border border-[#21262d] p-3 animate-in fade-in slide-in-from-bottom-2 shadow-lg shadow-black/40">
                                <div className="flex items-start justify-between gap-4">
                                    <div>
                                        <div className="text-[10px] font-bold text-amber-400 mb-1.5 flex items-center gap-1.5 uppercase tracking-wider">
                                            <AlertCircle size={12} />
                                            Approval Needed
                                        </div>
                                        {approvalContext.reason && (<div className="text-[11px] text-zinc-300 mb-1.5 leading-relaxed"><span className="text-zinc-500 font-medium">Reason:</span> {approvalContext.reason}</div>)}
                                        {approvalContext.command && (<div className="text-[11px] text-zinc-300 mb-1.5"><span className="text-zinc-500 font-medium">Action:</span> <code className="bg-black/40 px-1.5 py-0.5 rounded text-amber-200/90 font-mono border border-amber-500/20 shadow-sm ml-1">{approvalContext.command}</code></div>)}
                                        {approvalContext.risk && (<div className="text-[11px] text-zinc-300"><span className="text-zinc-500 font-medium">Risk:</span> {approvalContext.risk}</div>)}
                                    </div>
                                </div>
                                <div className="flex items-center gap-3 mt-3">
                                    <button
                                        onClick={() => handleApproval(true)}
                                        disabled={llmLoading}
                                        className="flex-1 px-3 py-2 bg-emerald-500/10 hover:bg-emerald-500/20 border border-emerald-500/30 hover:border-emerald-500/50 text-emerald-400 text-xs font-bold rounded-lg transition-all flex items-center justify-center gap-2 hover:shadow-lg hover:shadow-emerald-900/20 active:scale-95 disabled:opacity-50 disabled:cursor-not-allowed uppercase tracking-wide"
                                    >
                                        <CheckCircle2 size={14} />
                                        Approve & Execute
                                    </button>
                                    <button
                                        onClick={() => handleApproval(false)}
                                        disabled={llmLoading}
                                        className="flex-1 px-3 py-2 bg-red-500/10 hover:bg-red-500/20 border border-red-500/30 hover:border-red-500/50 text-red-400 text-xs font-bold rounded-lg transition-all flex items-center justify-center gap-2 hover:shadow-lg hover:shadow-red-900/20 active:scale-95 disabled:opacity-50 disabled:cursor-not-allowed uppercase tracking-wide"
                                    >
                                        <XCircle size={14} />
                                        Deny
                                    </button>
                                </div>
                            </div>
                        )}
                        {agentHints.length > 0 && (
                            <div className="bg-[#0d1117] rounded-lg border border-[#21262d] p-3">
                                <div className="text-[10px] font-medium text-zinc-300 mb-2">Hints</div>
                                <ul className="space-y-1">
                                    {agentHints.map((h, i) => (<li key={i} className="text-[11px] text-cyan-300">{h}</li>))}
                                </ul>
                                <div className="mt-2">
                                    <button
                                        onClick={() => sendMessage('[EXTEND] Apply hint and extend: act on emitted hint, expand coverage, use alternate tools, and reassess hypotheses.')}
                                        className="px-3 py-1.5 text-[11px] rounded-md bg-cyan-600/20 border border-cyan-500/40 hover:bg-cyan-600/30 text-cyan-200 transition-all"
                                    >
                                        Apply hint and extend
                                    </button>
                                </div>
                            </div>
                        )}
                    </div>
                </div>
            )}

            {/* Suggested Actions Chips - Hide in Claude Code mode */}
            {suggestedActions.length > 0 && !llmLoading && llmConfig.provider !== 'claude-code' && (
                <div className="px-4 pb-2 flex flex-wrap gap-2 animate-in fade-in slide-in-from-bottom-2 duration-300">
                    {suggestedActions.map((action, i) => (
                        <button
                            key={i}
                            onClick={() => sendMessage(action)}
                            className="px-3.5 py-1.5 text-xs bg-violet-500/10 border border-violet-500/30 hover:bg-violet-500/20 hover:border-violet-500/50 text-violet-300 rounded-full transition-all flex items-center gap-1.5 group"
                        >
                            <Sparkles size={10} className="text-violet-400 group-hover:animate-pulse" />
                            {action}
                        </button>
                    ))}
                </div>
            )}

            {/* Input - Hidden when Claude Code mode is active (ClaudeCodePanel has its own input) */}
            {llmConfig.provider !== 'claude-code' && (
                <div className="relative z-20 p-4 bg-[#16161a] border-t border-white/5">
                    <form onSubmit={(e) => { e.preventDefault(); sendMessage(userInput); }} className="flex items-center gap-2 p-1.5 bg-white/5 border border-white/10 rounded-full shadow-lg shadow-black/20 backdrop-blur-md focus-within:border-violet-500/30 focus-within:bg-white/10 transition-all duration-300">
                        <input
                            type="text"
                            value={userInput}
                            onChange={(e) => setUserInput(e.target.value)}
                            disabled={llmLoading || !llmStatus?.connected || !!llmStatus?.error}
                            placeholder={
                                (!llmStatus?.connected || !!llmStatus?.error)
                                    ? "Setup required to chat..."
                                    : "Ask about your cluster..."
                            }
                            className="flex-1 px-4 py-2 bg-transparent border-none text-white text-sm placeholder-zinc-500 focus:outline-none min-w-0 disabled:cursor-not-allowed disabled:text-zinc-600"
                        />
                        <button
                            type="submit"
                            disabled={llmLoading || !userInput.trim() || !llmStatus?.connected || !!llmStatus?.error}
                            className="p-2.5 rounded-full bg-gradient-to-r from-violet-600 to-fuchsia-600 hover:from-violet-500 hover:to-fuchsia-500 disabled:from-zinc-700 disabled:to-zinc-700 disabled:text-zinc-500 text-white transition-all duration-200 shadow-lg shadow-purple-500/20 hover:shadow-purple-500/30 disabled:shadow-none hover:scale-105 disabled:hover:scale-100 flex-shrink-0"
                        >
                            <Send size={16} className={llmLoading ? 'animate-pulse' : ''} />
                        </button>
                    </form>
                </div>
            )}
        </div>
    );

    if (embedded) return panelContent;
    return createPortal(panelContent, document.body);
}
